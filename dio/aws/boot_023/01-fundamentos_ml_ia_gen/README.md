# Bootcamp Nexa - Machine Learning para Iniciantes na AWS - Module 1   <img src="../0-aux/logo_boot.png" alt="boot_023" width="auto" height="45">

### Repository: [boot](../../../../)   
### Platform: <a href="../../../">dio   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/plataforma/dio.jpeg" alt="dio" width="auto" height="25"></a>   
### Software/Subject: <a href="../../">aws    <img src="https://cdn.jsdelivr.net/gh/devicons/devicon@latest/icons/amazonwebservices/amazonwebservices-original-wordmark.svg" alt="aws" width="auto" height="25"></a>
### Bootcamp: <a href="../">boot_023 (Bootcamp Nexa - Machine Learning para Iniciantes na AWS)   <img src="../0-aux/logo_boot.png" alt="boot_023" width="auto" height="25"></a>
### Module: 1. Fundamentos de Machine Learning e Ias Generativas 

---

This folder refers to Module 1 **Fundamentos de Machine Learning e Ias Generativas** from bootcamp [**Bootcamp Nexa - Machine Learning para Iniciantes na AWS**](../).

### Theme:
- Cloud Computing
- Artificial Intelligence (AI)
- Machine Learning (ML)

### Used Tools:
- Operating System (OS): 
  - Linux   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/linux/linux-original.svg" alt="linux" width="auto" height="25">
  - Windows 11   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/windows11.png" alt="windows11" width="auto" height="25">
- Cloud:
  - AWS   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon@latest/icons/amazonwebservices/amazonwebservices-original-wordmark.svg" alt="aws" width="auto" height="25">
- Cloud Services:
  - Google Drive   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/google_drive.png" alt="google_drive" width="auto" height="25">
- Language:
  - HTML   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/html5/html5-original.svg" alt="html" width="auto" height="25">
  - Markdown   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/markdown/markdown-original.svg" alt="markdown" width="auto" height="25">
- Integrated Development Environment (IDE) and Text Editor:
  - Visual Studio Code (VS Code)   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/vscode/vscode-original.svg" alt="vscode" width="auto" height="25">
- Versioning: 
  - Git   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/git/git-original.svg" alt="git" width="auto" height="25">
- Repository:
  - GitHub   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/github/github-original.svg" alt="github" width="auto" height="25">

---

### Bootcamp Module 1 Structure
1. <a name="item1">Fundamentos de Machine Learning e Ias Generativas</a><br>
  1.1. Bootcamp DIO: Educação Gratuita e Empregabilidade Juntas!<br>
  1.2. <a href="#item1.2">Algoritmos e Aprendizado de Máquina</a><br>
  1.1. <a href="#item1.3">Processamento de Linguagem Natural</a><br>
  1.4. <a href="#item1.4">O que são IAs Generativas</a><br>
  1.5. <a href="#item1.5">Aula Inaugural: Bootcamp Nexa - Machine Learning para Iniciantes na AWS</a><br>

---

### Objective:
O objetivo deste módulo do bootcamp foi introduzir conceitos fundamentais para melhor compreensão da Inteligência Articial. Conceitos como IA Geral, IA Restrita, Machine Learning (Aprendizado Profundo), Deep Learning, Redes Neurais, IAs Generativas, Processamento de Linguagem Natural, foram abordados. Também foi detalhado minuciosamente como são divididas as redes neurais e que a partir delas surgem as IAs Generativas.

### Structure:
A estrutura das pastas obedeceu a estruturação do bootcamp, ou seja, conforme foi necessário, sub-pastas foram criadas para os cursos específicos deste módulo. Na imagem 01 é exibido a estruturação das pastas. 

<div align="Center"><figure>
    <img src="../0-aux/md3-img01.png" alt="img01"><br>
    <figcaption>Imagem 01.</figcaption>
</figure></div><br>

### Development:
O desenvolvimento deste módulo do bootcamp foi dividido em três cursos e uma . Abaixo é explicado o que foi desenvolvido em cada uma dessas atividades.

<a name="item1.2"><h4>1.2 Algoritmos e Aprendizado de Máquina</h4></a>[Back to summary](#item1) | <a href="https://github.com/PedroHeeger/main/blob/main/cert_ti/04-curso/cloud/aws/(23-09-09)_AWS_Official_Content-Introducao...AWS_PH_DIO.pdf">Certificate</a>

A inteligência artificial teve suas origens na ficção científica. O primeiro robô foi criado para uma peça de teatro, dando origem ao termo "robótica". A partir desse ponto, a ideia evoluiu até o surgimento dos primeiros robôs industriais, que consistiam em braços robóticos utilizados para pintar, cortar, soldar e transportar peças. Atualmente, existem diversos tipos de robôs para aplicações específicas. A escolha por braços robóticos em vez de robôs humanóides se deve à complexidade envolvida na construção de um robô humanóide, algo que era inviável na época devido à falta de sensores especializados. Esses robôs antigos não possuíam o que se conhece como IA Geral, ao invés disso utilizavam a IA Restrita.

A Inteligência Artificial (IA) Geral é uma forma de IA que imita o comportamento humano em uma ampla gama de atividades, realizando tanto tarefas básicas quanto específicas. Essa tecnologia ainda não está disponível; atualmente, existe apenas a IA Restrita. Esta IA é projetada para realizar tarefas específicas que os humanos executam, mas não possui a capacidade de realizar atividades fora dessas tarefas. Em contraste, a IA Geral, ou simplesmente IA, é capaz de generalizar e realizar tarefas além daquelas para as quais foi originalmente treinada.

O Teste de Turing avalia a capacidade de uma máquina de exibir comportamento inteligente equivalente ao de um ser humano, ou indistinguível deste. Um humano interage com a máquina com IA para determinar se consegue diferenciá-la de um ser humano. O primeiro robô a obter cidadania foi Sophia, capaz de reproduzir 62 expressões faciais. O objetivo era aumentar a aceitação da robótica no ambiente humano. No entanto, Sophia ainda não conseguiu passar no Teste de Turing.

O Machine Learning (ML), ou aprendizado de máquina, é a técnica de treinar um sistema para que ele adquira inteligência, transformando-o em uma IA Restrita. No entanto, após o treinamento, a máquina ou computador pode ainda não ser suficientemente inteligente para ser considerado uma IA Restrita. Um exemplo disso é o reconhecimento facial: se o sistema, após o treinamento, não conseguir identificar rostos, significa que ele não aprendeu adequadamente e, portanto, não é uma inteligência artificial restrita. O Machine Learning é a base da IA, com a finalidade de desenvolver máquinas que pensem como humanos, treinando seus sistemas para que adquiram inteligência e possam imitar o pensamento humano. Ele visa programar computadores para aprender automaticamente comportamentos ou padrões a partir de exemplos ou observações, geralmente utilizando uma base de conhecimento fornecida por DataSets. No ML, a tomada de decisão é baseada em regras bem definidas, sem influência de emoções. A automação é utilizada para corrigir e apoiar falhas humanas. Em resumo, o Machine Learning é o processo de aprendizagem de sistemas, máquinas ou computadores, tornando-os inteligentes o suficiente para serem considerados IA Restrita. 

As tecnologias atuais de Inteligência Artificial (IA) são inspiradas na inteligência humana e animal. Por exemplo, as redes de conhecimento de imagens foram desenvolvidas com base no funcionamento cerebral dos gatos. No entanto, as técnicas de aprendizado são mais semelhantes ao que ocorre nos seres humanos. A IA utiliza conceitos de neurônios, e as redes neurais formam a base para sistemas inteligentes. O comportamento cerebral é traduzido em algoritmos matemáticos que imitam esse funcionamento. Esses neurônios virtuais geram inteligência por meio do treinamento. No Machine Learning, existem diferentes métodos de treinamento, como o aprendizado por reforço. Nesse método, uma pontuação positiva (1) é atribuída quando a IA realiza a tarefa corretamente, e uma pontuação negativa (-1) é dada quando a tarefa não é realizada, representando a avaliação do desempenho da IA.

Alguns casos de usos de sistemas inteligentes, ou seja, sistemas que possuem uma IA Restrita, são listados abaixo subdivididos por áreas específicas:
- Saúde:
  - Diagnóstico de Doenças: Análise de imagens médicas para detectar câncer; 
  - Assistentes Virtuais: Chatbots para responder perguntas dos pacientes;
  - Gerenciamento de Registros Médicos: Análise de dados para prever readmissões hospitalares.
- Finanças:
  - Detecção de Fraudes: Monitoramento de transações para identificar atividades suspeitas;
  - Consultoria Financeira Automatizada: Robo-advisors que recomendam investimentos;
  - Análise de Crédito: Avaliação de risco de crédito com base em dados históricos. 
- Varejo:
  - Recomendação de Produtos: Sistemas que sugerem produtos com base no comportamento de compra;
  - Gestão de Inventário: Previsão de demanda para otimizar o estoque;
  - Atendimento ao Cliente: Chatbots para suporte ao cliente em tempo real.
- Tranporte:
  - Veículos Autônomos: Carros que dirigem sozinhos utilizando IA;
  - Otimização de Rotas: Algoritmos que calculam a rota mais eficiente para entregas;
  - Previsão de Manutenção: Análise de dados para prever falhas em veículos.
- Educação:
  - Tutoria Personalizada: Sistemas que adaptam o ensino às necessidades individuais dos alunos;
  - Correção Automática: Ferramentas que corrigem provas e trabalhos automaticamente;
  - Análise de Desempenho: Identificação de padrões no desempenho dos alunos para intervenção precoce.
- Agricultura:
  - Monitoramento de Culturas: Drones com IA para monitorar a saúde das plantações;
  - Previsão de Colheitas: Modelos que preveem o rendimento das colheitas;
  - Gestão de Irrigação: Sistemas que otimizam a quantidade de água usada com base em dados climáticos.
- Marketing:
  - Análise de Sentimento: Avaliação de sentimentos em redes sociais para campanhas de marketing;
  - Segmentação de Mercado: Identificação de segmentos de clientes com base em comportamento e preferências;
  - Personalização de Conteúdo: Adaptação de conteúdo publicitário para diferentes públicos-alvo.
- Recursos Humanos:
  - Triagem de Currículos: Ferramentas que analisam e selecionam candidatos para entrevistas;
  - Engajamento de Funcionários: Análise de dados para medir e melhorar o engajamento dos funcionários;
  - Desenvolvimento de Carreira: Sistemas que recomendam treinamentos e oportunidades de crescimento.
- Segurança:
  - Vigilância por Vídeo: Análise de vídeos para detectar atividades suspeitas;
  - Detecção de Intrusos: Sensores e IA para identificar invasões em tempo real;
  - Autenticação Biométrica: Reconhecimento facial ou de impressões digitais para acesso seguro.
- Energia:
  - Previsão de Demanda: Modelos que preveem o consumo de energia;
  - Otimização de Rede: Algoritmos que equilibram a carga nas redes elétricas;
  - Manutenção Preditiva: Análise de dados de sensores para prever falhas em equipamentos.
- Indústria:
  - Manutenção Preditiva: Análise de dados de sensores para prever e prevenir falhas em máquinas e equipamentos;
  - Automação de Processos: Robôs industriais e sistemas de controle automatizados que otimizam a produção e reduzem erros;
  - Inspeção de Qualidade: Visão computacional para identificar defeitos em produtos durante o processo de fabricação.
- Indústria Alimentícia:
  - Reconhecimento do Tipo de Carne: Utilização de visão computacional para identificar e classificar diferentes tipos de carne;
  - Controle de Qualidade: Análise de produtos para garantir que atendem aos padrões de segurança e qualidade;
  - Otimização da Cadeia de Suprimentos: Previsão de demanda e otimização de estoques para reduzir desperdícios e garantir a disponibilidade de produtos.
- Big Data:
  - Análise Preditiva: Uso de modelos de aprendizado de máquina para analisar grandes volumes de dados e prever tendências futuras;
  - Detecção de Anomalias: Identificação de padrões incomuns em grandes conjuntos de dados para detectar fraudes, falhas de sistema ou comportamentos anômalos;
  - Processamento de Linguagem Natural (NLP): Análise de grandes volumes de texto para extrair insights, entender sentimentos e identificar tópicos relevantes.
- Transhumanismo:
  - Próteses Inteligentes: Desenvolvimento de próteses controladas por IA que se adaptam ao movimento e às necessidades do usuário, proporcionando maior mobilidade e funcionalidade;
  - Interface Cérebro-Computador (BCI): Utilização de IA para interpretar sinais cerebrais e permitir que pessoas controlem dispositivos externos, como computadores ou cadeiras de rodas, diretamente com o pensamento;
  - Aprimoramento Cognitivo: Aplicação de IA para criar assistentes virtuais que ajudam a melhorar a memória, a concentração e outras funções cognitivas através de estímulos personalizados e análise de padrões de comportamento.

Não é obrigatório que quem trabalha com Machine Learning também trabalhe com Inteligência Artificial, e vice-versa. É possível atuar em projetos focados exclusivamente em Machine Learning, exclusivamente em Inteligência Artificial, ou em projetos que envolvem ambos. A Inteligência Artificial abrange qualquer técnica que permita a um computador imitar a inteligência humana, utilizando lógica, regras matemáticas, árvores de decisão e Machine Learning, incluindo deep learning. A IA é o campo dedicado ao desenvolvimento de programas computacionais com a capacidade de aprender e raciocinar como os humanos, visando resolver problemas de forma criativa.

Machine Learning é um subconjunto da Inteligência Artificial que utiliza técnicas estatísticas para permitir que máquinas melhorem o desempenho em tarefas com base na experiência. Isso inclui o Deep Learning. Trata-se de uma aplicação da IA voltada para a criação de algoritmos que possibilitam que os sistemas aprendam sem intervenção humana direta, ou seja, sem necessidade de programação explícita. Deep Learning, por sua vez, é um subconjunto de Machine Learning que utiliza algoritmos para permitir que o software se treine autonomamente para executar tarefas, como reconhecimento de imagem e voz, através de múltiplas camadas de redes neurais artificiais. Esse campo foca na criação de redes neurais artificiais, sistemas que imitam o funcionamento do cérebro humano, adaptando-se e aprendendo a partir de grandes volumes de dados. O Deep Learning é na prática a utilização de redes neurais artificiais deep (profundas).

<a name="item1.3"><h4>1.3 Processamento de Linguagem Natural</h4></a>[Back to summary](#item1) | <a href="https://github.com/PedroHeeger/main/blob/main/cert_ti/04-curso/cloud/aws/(23-09-11)_Introducao...Conceito...Cloud_PH_DIO.pdf">Certificate</a>

O Processamento de Linguagem Natural (NLP) é um campo da computação que integra inteligência artificial e algoritmos avançados. Ele permite que os computadores compreendam, interpretem e manipulem a linguagem humana. O NLP é facilitado por redes de Deep Learning, que são redes neurais profundas. Esses algoritmos sofisticados são responsáveis por interpretar a fala humana e possibilitam o reconhecimento de voz pelos sistemas. Entre as aplicações atuais do NLP estão sistemas de recomendação, comandos por voz e chatbots. O processamento de linguagem é dividido em quatro níveis: Morfológico, Sintático, Semântico e Pragmático. A Pragmática, um ramo da linguística, estuda a linguagem no contexto de sua utilização na comunicação, analisando detalhadamente a composição, derivação, flexão das palavras e seus processos de formação.

Os sistemas de NLP (Processamento de Linguagem Natural) permitem que a tecnologia não apenas compreenda o significado literal de cada palavra, mas também leve em conta aspectos como o contexto da conversa, significados sintáticos e semânticos, interpretação de textos, análise de sentimentos e mais. Inicialmente, os modelos de linguagem usavam arquiteturas de redes neurais (NN) feedforward ou convolucionais (CNN), que não capturavam bem o contexto das palavras na frase. Para melhorar essa captura de contexto, foram aplicadas redes neurais recorrentes (RNNs). Posteriormente, o LSTM (Long Short-Term Memory), uma variante do RNN, foi desenvolvido para capturar o contexto de longa distância. O LSTM bidirecional (BiLSTM) aprimora o LSTM ao analisar as sequências de palavras tanto na direção para frente quanto para trás.

O **Google** substituiu seu sistema de tradução baseado em frases pela **Neural Machine Translation (NMT)**, reduzindo os erros de tradução em 60%. A NMT utiliza uma rede LSTM profunda com 8 camadas de codificador e 8 camadas de decodificador. A revolução no campo de NLP com Deep Learning começou em 2018 com o lançamento dos modelos de linguagem pré-treinados ELMo e ULMFiT. No entanto, foi a introdução da arquitetura Transformer, que utiliza exclusivamente mecanismos de atenção, que transformou as pesquisas na área. A arquitetura Transformer permitiu o treinamento com volumes de dados muito maiores do que antes, levando ao desenvolvimento de modelos de linguagem pré-treinados que são ajustados finamente (fine-tuning) para tarefas específicas de linguagem. Os word embeddings fornecem representações vetoriais das palavras, capturando o contexto e o relacionamento entre elas nos documentos, sem a necessidade de engenharia de características com anotações detalhadas.

O evento ImageNet, em 2012, marcou o início de um grande interesse global por Deep Learning, enquanto 2018 sinalizou a revolução na NLP com modelos de linguagem pré-treinados como ELMo, GPT e BERT, que trouxeram avanços significativos em tarefas como inferência, análise de sentimentos e tradução de linguagem em um curto período.

<a name="item1.4"><h4>1.4 O que são IAs Generativas</h4></a>[Back to summary](#item1) | <a href="https://github.com/PedroHeeger/main/blob/main/cert_ti/04-curso/cloud/aws/(23-09-11)_Infraestrutura_Global_AWS_PH_DIO.pdf">Certificate</a>

As redes neurais biológicas são compostas por neurônios reais localizados no sistema nervoso de organismos vivos. Em contraste, as Redes Neurais Artificiais (ANN ou RNA), também conhecidas simplesmente como Redes Neurais (NN), são modelos computacionais inspirados na estrutura e funcionamento das redes neurais biológicas, especialmente no cérebro humano, mas implementadas em software ou hardware. Essas redes são projetadas para resolver problemas computacionais e são formadas por camadas de neurônios artificiais que processam informações. Os neurônios artificiais são as unidades básicas de uma rede neural, modelados segundo o funcionamento dos neurônios biológicos, mas em formato computacional. Cada neurônio artificial recebe entradas, aplica pesos a essas entradas, calcula uma soma ponderada, passa o resultado por uma função de ativação e gera uma saída.

As redes neurais são divididas em três camadas principais. A camada de entrada (Input Layer) recebe múltiplas entradas, que representam características ou dados, e associa cada entrada a um peso. As camadas ocultas (Hidden Layers) processam os dados aplicando pesos e funções de ativação. A camada de saída (Output Layer) fornece o resultado da função de ativação, que pode ser passado para a próxima camada ou ser a saída final da rede. Cada entrada é multiplicada por um peso que ajusta sua importância no cálculo final. Os pesos são ajustados durante o treinamento para melhorar a precisão do modelo. A soma ponderada calcula a soma dos produtos das entradas e seus pesos. A função de ativação introduz não-linearidade ao modelo, permitindo que a rede neural aprenda relações complexas nos dados. O treinamento da rede utiliza algoritmos de otimização, como o algoritmo de retropropagação, para ajustar os pesos e minimizar os erros.

As redes neurais podem ser classificadas com base na profundidade (extensão da rede) de duas formas principais. Redes Neurais Artificiais Rasas (RNA Rasas ou Shallow ANNs), também conhecidas como Redes Neurais Rasas (Shallow Neural Networks (SNN)), têm uma estrutura relativamente simples, geralmente composta por uma camada de entrada, uma ou duas camadas ocultas e uma camada de saída. Já as Redes Neurais Artificiais Profundas (Redes Neurais Profundas ou Deep Neural Networks (DNNs)) apresentam múltiplas camadas ocultas entre a camada de entrada e a camada de saída, permitindo um nível mais profundo de abstração e aprendizado. Quanto maior a profundidade, maior o número de camadas ocultas entre a camada de entrada e a de saída, tornando-se uma rede mais extensa. Quanto mais extensa a rede, maior o nível de complexidade dela.

Um algoritmo é um conjunto de procedimentos ou regras utilizados para treinar uma rede neural e otimizar seus parâmetros. O termo Algoritmo Neural ou Algoritmo Neural Artificial refere-se a diversos algoritmos relacionados ao funcionamento das redes neurais, especialmente aqueles envolvidos no treinamento e na otimização dos modelos de redes neurais artificiais.

Os tipos mais comuns de redes neurais artificiais tradicionais são os seguintes:
- Feedforward Neural Networks (FFNNs): Caracterizam-se pelo fluxo unidirecional de informações, onde os dados se movem apenas da camada de entrada para a camada de saída, passando pelas camadas ocultas.
- Convolutional Neural Networks (CNNs): Especializadas no processamento de dados com estrutura de grade, como imagens, e são amplamente utilizadas para tarefas de visão computacional.
- Recurrent Neural Networks (RNNs): Projetadas para processar dados sequenciais, essas redes mantêm um estado interno que captura informações de entradas anteriores, facilitando o tratamento de sequências temporais ou contextuais.

As redes generativas surgiram para atender à necessidade de criar novos conteúdos digitais que não estão presentes nas bases de dados existentes. Baseadas em redes neurais artificiais (RNA), essas redes utilizam algoritmos inspirados nas redes neurais biológicas. Diferentemente das redes neurais tradicionais, que se concentram em tarefas como classificação, regressão ou previsão, as redes generativas são projetadas para criar dados novos e sintéticos que imitam dados reais. Elas podem ser rasas ou profundas, dependendo da arquitetura e da complexidade dos dados que precisam gerar. As redes generativas podem ser divididas em três tipos:
- Redes Generativas Adversárias (GANs): Essas redes generativas utilizam dois algoritmos neurais distintos, o Gerador e o Discriminador, que trabalham em oposição para alcançar um objetivo comum.
  - Gerador: Cria novos dados a partir de uma entrada aleatória (ruído), com o objetivo de gerar dados que se assemelhem aos reais.
  - Discriminador: Funciona como um "crítico" que avalia a autenticidade dos dados, tentando distinguir entre os dados reais e os gerados pelo Gerador.
- Modelos de Difusão: Esses modelos geram dados novos começando com dados adicionados de ruído e, em seguida, refinam esses dados até que se assemelhem aos dados de treinamento.
- Redes Neurais Variacionais (VAEs): Utilizam um modelo probabilístico para criar novos dados com base na distribuição aprendida a partir dos dados de treinamento.

Além das redes neurais artificiais tradicionais e das redes neurais generativas, existem outras categorias de redes neurais:
- Memory Networks (Redes Neurais de Memória): Incorporam uma memória externa para armazenar e acessar informações de longo prazo.
- Attention Mechanisms (Mecanismos de Atenção): Permitem que a rede se concentre em partes específicas da entrada, melhorando o desempenho em tarefas como tradução e reconhecimento de fala.
  - Redes Transformers: Arquitetura de rede neural generativa que utiliza mecanismos de atenção para processar dados sequenciais. Introduzida no paper "Attention is All You Need" por Vaswani et al. em 2017, inclui modelos como:
    - **Bidirectional Encoder Representations from Transformers (BERT)**: Modelo pré-treinado que usa atenção bidirecional para capturar o contexto completo de palavras ou tokens em uma frase.
    - **Generative Pre-trained Transformer (GPT)**: Modelo baseado em Transformer treinado para gerar texto coerente e contextual. A versão mais recente é o GPT-4.
    - **Text-To-Text Transfer Transformer (T5)**: Modelo que aborda todas as tarefas de processamento de linguagem natural como problemas de tradução de texto para texto.
- Neural Symbolic Systems (Sistemas Neurais Simbólicos): Combinam redes neurais com raciocínio simbólico para melhorar a interpretação e manipulação de informações complexas.
- Redes Neurais Autoencoders: Utilizadas para aprender representações compactas dos dados, frequentemente para redução de dimensionalidade ou denoising.
  - Variational Autoencoders (VAEs): Versão avançada de autoencoder para geração de dados.
- Graph Neural Networks (GNNs) ou Redes Neurais de Grafos: Projetadas para lidar com dados estruturados em grafos, representando informações como nós e arestas.
- Spiking Neural Networks (SNNs) ou Redes Neurais Espinossomáticas: Modelam o comportamento dos neurônios biológicos com base em spikes para representar informações.

As Redes Bayesianas, apesar de estarem associadas à inteligência artificial, não se enquadram como redes neurais. Elas são modelos gráficos probabilísticos que representam relações de dependência condicional entre variáveis por meio de um gráfico dirigido acíclico (DAG). Cada nó no gráfico representa uma variável, e cada aresta indica uma relação de dependência condicional entre essas variáveis. Portanto, Redes Bayesianas não são consideradas um tipo de rede neural.

Deepfake é uma técnica de inteligência artificial que emprega redes neurais artificiais para criar ou alterar vídeos e áudios, simulando de maneira convincente a aparência e a voz de uma pessoa. Essa técnica utiliza principalmente Redes Neurais Generativas Adversariais (GANs) ou Autoencoders Variacionais para gerar conteúdo visual e auditivo falso que parece autêntico. O termo "deepfake" resulta da combinação de "deep learning" (aprendizado profundo), já que as redes neurais utilizadas são complexas, logo tendem a ser redes profundas, e "fake" (falso), indicando o uso de técnicas avançadas de IA para produzir mídias que podem ser difíceis de distinguir de conteúdos reais.

<div align="Center"><figure>
    <img src="../0-aux/md3-img02.png" alt="img02"><br>
    <figcaption>Imagem 02.</figcaption>
</figure></div><br>


<a name="item1.5"><h4>1.5 Aula Inaugural: Bootcamp Nexa - Machine Learning para Iniciantes na AWS</h4></a>[Back to summary](#item1) | <a href="https://github.com/PedroHeeger/main/blob/main/cert_ti/04-curso/cloud/aws/(23-09-12)_Computacao...AWS_PH_DIO.pdf">Certificate</a>




