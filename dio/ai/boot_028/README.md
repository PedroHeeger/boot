# Bootcamp Nexa - Fundamentos de IA Generativa e Claude 3   <img src="./0-aux/logo_boot.png" alt="boot_028" width="auto" height="45">

### Repository: [boot](../../../)   
### Platform: <a href="../../">dio   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/plataforma/dio.jpeg" alt="dio" width="auto" height="25"></a>   
### Software/Subject: <a href="../">ai   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/content/ai.jpg" alt="ai" width="auto" height="25"></a>
### Bootcamp: <a href="./">boot_028 (Bootcamp Nexa - Fundamentos de IA Generativa e Claude 3)   <img src="./0-aux/logo_boot.png" alt="boot_028" width="auto" height="25"></a>

#### <a href="https://github.com/PedroHeeger/main/blob/main/cert_ti/03-conclu/ai/(24-08-12)_Cert_Formacao_Fundamentos...IA_PH_DIO.pdf">Certificate</a>

---

### Theme:
- Artificial Intelligence (AI)
- Machine Learning (ML)

### Used Tools:
- Operating System (OS): 
  - Windows 11 <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/windows11.png" alt="windows11" width="auto" height="25">
- Cloud Services:
  - Google Drive <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/google_drive.png" alt="google_drive" width="auto" height="25">
- Language:
  - HTML   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/html5/html5-original.svg" alt="html" width="auto" height="25">
  - Markdown   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/markdown/markdown-original.svg" alt="markdown" width="auto" height="25">
- Integrated Development Environment (IDE) and Text Editor:
  - Visual Studio Code (VS Code)   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/vscode/vscode-original.svg" alt="vscode" width="auto" height="25">
- Versioning: 
  - Git   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/git/git-original.svg" alt="git" width="auto" height="25">
- Repository:
  - GitHub   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/github/github-original.svg" alt="github" width="auto" height="25">
- Artificial Intelligence:
  - D-iD   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/sites/d-id.png" alt="d-id" width="auto" height="25">

---

### Bootcamp Structure
1. <a name="item1">Introdução ao Mundo da Inteligência Artificial (IA) Generativa</a>    
  1.1. Bootcamp DIO: Educação Gratuita e Empregabilidade Juntas!<br>
  1.2. [Introdução à Inteligência Artificial](https://github.com/PedroHeeger/boot/tree/main/dio/ai/boot_024#item1.1)   
  1.3. [Aplicações e Impacto da IA no Mundo Atual](https://github.com/PedroHeeger/boot/tree/main/dio/ai/boot_024#item1.2)   
  1.4. Mentoria: Aula Inaugural - Bootcamp Nexa Fundamentos de IA Generativa e Claude 3<br> 
2. <a name="item2">Explorando IAs Generativas na AWS</a>   
  2.1. <a href="#item2.1">Mentoria: Amazon Bedrock: A Nova Era da Inteligência Artificial Generativa</a><br>
  2.2. <a href="#item2.2">Mentoria: Dominando IA Generativa com Claude 3 no Amazon Bedrock</a><br>
  2.3. <a href="#item2.3">Mentoria: Amazon Q: IA Generatica como Copiloto de Programação Python</a><br>
  2.4. Desafios de Código: Aperfeiçoe Sua Lógica e Pensamento Computacional<br>
  2.5  <a href="#item2.5">Desafio de Código: Treinando Desafios de Códigos com IAs Generativas</a><br>
  2.6. Desafios de Projetos: Crie Um Portfólio Vencedor<br>
  2.7. [Desafio de Projeto: Natural ou Fake Natty? Como Vencer na Era das Ias Generativas!](https://github.com/PedroHeeger/boot/tree/main/dio/ai/boot_024#item2.2)   
---

### Objective:
Segue abaixo o objetivo deste bootcamp, conforme descrito na plataforma da **DIO**.
  
>Com uma introdução sólida não somente a Inteligência Artificial Generativa, mas um verdadeiro guia de como aplicá-la nas demandas reais do seu dia a dia, o bootcamp chegou para somar no conhecimento dos serviços mais utilizados da AWS na área.

>Conheça o Amazon Q, o Bedrock e o Claude 3 e adicione essas habilidades no seu currículo, aplicando o que aprendeu de forma prática para criar soluções com mais rapidez e eficiência.

>Nesta trilha, você vai desenvolver suas habilidades com projetos práticos, desafios de códigos e mentorias com experts da DIO e, além disso, ficará disponível na Talent Match para tech recrutadores de empresas parceiras que procuram profissionais com esse perfil.

### Structure:
- A estrutura do bootcamp da plataforma **DIO** é dividida em módulos e cada módulo contém cursos e desafios, sendo este último podendo ser **Desafio de Projeto** ou **Desafio de Código**. 
- Para melhor organização deste bootcamp, a estruturação das pastas acompanhou a estrutura do bootcamp. Dessa forma, foram criadas sub-pastas para cada módulo ou curso desse bootcamp, sendo que nas sub-pastas dos módulos estão contidas as pastas ou arquivos dos desafios ou cursos realizados.
- Nos arquivos de README de cada módulo ou curso está descrito o que foi realizado em cada um, e podem ser acessado nos links clicáveis na opção **Bootcamp Strucutre**. Os links que não forem clicáveis, são de cursos ou módulos que, na sua maior parte ou inteiramente, foram assuntos teóricos e não possuem materiais.
- Alguns cursos podem ter sido desenvolvidos em outro bootcamp, já que são os mesmos cursos, portanto, a explicação sobre esses cursos e seus respectivos materiais vão está no outro bootcamp e podem ser acessados através dos links do **Bootcamp Structure**.
- A sub-pasta **0-aux** foi criada apenas para armazenar imagens auxiliares para a construção dos arquivos de README.md deste bootcamp.

### Development:
Cada desafio ou cursos tiveram seus desenvolvimentos específicos. Portanto, a explicação sobre cada uma deles está contida no README da sua respectiva pasta, que podem está armazenadas neste bootcamp ou em outros se já tiverem sido realizados anteriormente. Caso haja poucas atividades restantes a serem feitas para conclusão deste bootcamp, o desenvolvimento dessas atividades estará aqui abaixo, não sendo necessário a criação de sub-pastas.

<a name="item2.1"><h4>2.1 Mentoria: Amazon Bedrock: A Nova Era da Inteligência Artificial Generativa</h4></a>[Back to summary](#item2) | <a href="https://github.com/PedroHeeger/main/blob/main/cert_ti/04-curso/ai/(24-09-06)_Ment_Amazon_Bedrock...IA_Generativa_PH_DIO.pdf">Certificate</a>

A inteligência artificial (IA) refere-se à capacidade de máquinas de aprenderem com a experiência e tomarem decisões de forma autônoma e inteligente. Ela busca replicar a inteligência humana, permitindo que sistemas façam escolhas com base em dados e padrões, muitas vezes de natureza estatística. A IA Generativa, um tipo específico de IA, é capaz de criar textos, imagens e outros conteúdos a partir de solicitações em linguagem natural. Com um potencial transformador, a IA Generativa vem impactando diversos aspectos da vida cotidiana, mas é essencial que seja usada de maneira responsável, evitando a disseminação de desinformação e a produção de conteúdos prejudiciais. Esses modelos são treinados em vastos conjuntos de dados, aprendendo padrões e as relações entre diferentes elementos.

O **Amazon Bedrock** é uma plataforma da **Amazon Web Services (AWS)** que oferece uma variedade de modelos de IA voltados para diversas tarefas, como geração de texto, pesquisa, criação de imagens, tradução e até mesmo desenvolvimento de código. Esses modelos são chamados de modelos de base, ou Foundations Models (FMs). Uma das principais vantagens do **Amazon Bedrock** está na sua simplicidade de uso. A plataforma permite a escolha entre alguns dos mais renomados modelos do mercado, como **Jurassic** da AI-21Labs, Command-Inbad da Cohere, **Llama** da **Meta**, **Amazon Titan** da **AWS** e **Claude 3** da **Anthropic**.

O **Amazon Bedrock** oferece a possibilidade de experimentar diferentes modelos de base por meio de playgrounds interativos para texto, chat e imagem, facilitando a escolha do modelo mais adequado para cada caso de uso. Outro destaque é a avaliação de modelos, que pode ser feita de forma automática ou com intervenção humana, utilizando métricas como precisão, robustez, tokenicidade e até métricas personalizadas. A personalização dos modelos de base é realizada de maneira privada, utilizando técnicas como ajuste fino e pré-treinamento contínuo, garantindo que os dados específicos de uma empresa sejam usados para ajustar uma cópia do modelo às suas necessidades. Um aspecto interessante para desenvolvedores no **Amazon Bedrock** é a API unificada, que permite realizar inferências com qualquer modelo escolhido, mantendo o acesso às versões mais recentes sem a necessidade de grandes mudanças no código.

Dois principais casos de uso foi apresentado nesta mentoria:
- Indústria: Resolução de problemas para melhorar a produtividade dos técnicos. Um bom exemplo são seguradoras de veículos ou empresas que alugam equipamentos e/ou maquinarios. Arquitetura: Sistemas Finais (Mobile) => (REST API + Prompt) => Amazon API Gateway => Prompt envia eventos => AWS Lambda (Funções Lambda) => Prompt + Parâmetros de Inferência => Amazon Bedrock => Envia Prompt ao FM => Cohere.
- Mídia e Entretenimento: Geração de Poster de um filme ficticio ou propaganda de algum produto. Ideal: Através de um sistema ser capaz de gerar imagens para uso na Publicidade e Marketing => Envia informações ao Prompt => Amazon Bedrock (Stability.AI) => ou Amazon S3 Bucket => Disponibiliza imagem ao sistema => Repete. Arquitetura: Sistemas Finais (Mobile) => (REST API + Prompt) => Amazon API Gateway => Prompt envia eventos => Lambda Function => Prompt + Parametros de Inferência => Amazon Bedrock (<=> Stability.AI) => Disponibiliza a Imagem => Amazon S3 Bucket => Retorna como resposta a URL do Objeto (Imagem) => Amazon API Gateway => Com a URL da imagem, o usuário acessa o objeto => Amazon S3 Bucket.

Durante a mentoria, dois casos de uso principais foram explorados, cada um aproveitando as ferramentas da **AWS** para resolver desafios específicos em setores distintos:
- Indústria: O foco aqui é a otimização da produtividade dos técnicos, particularmente em setores como seguradoras de veículos ou empresas que alugam equipamentos e maquinário. O projeto envolve o atendimento de incidentes de primeiro nível, onde um técnico recebe detalhes do problema, como uma imagem do incidente, e essa informação é processada automaticamente para gerar um relatório. A arquitetura é composta por sistemas móveis que enviam os detalhes via REST API. Essa API passa pelo **Amazon API Gateway**, que dispara eventos para o **AWS Lambda**. A função Lambda então processa os prompts com parâmetros de inferência e os encaminha ao **Amazon Bedrock**, onde um modelo de base (como o da **Cohere**) analisa o incidente e gera um relatório para um técnico especializado. Isso facilita a identificação rápida de problemas e agiliza a resolução de incidentes.
- Mídia e Entretenimento: Este caso de uso está voltado para a geração automática de pôsteres de filmes fictícios ou material publicitário para produtos. O objetivo é utilizar a IA para criar imagens promocionais, automatizando o processo criativo em campanhas de marketing. A arquitetura começa com sistemas móveis que enviam as informações via REST API para o **Amazon API Gateway**. O gateway, por sua vez, envia eventos para funções **AWS Lambda**, que processam os prompts com parâmetros de inferência e os repassam ao **Amazon Bedrock**, utilizando modelos como o **Stability.AI** para gerar imagens. Essas imagens são armazenadas no Amazon S3, e a URL do objeto é retornada ao sistema via API Gateway. Com a URL, o usuário pode acessar a imagem diretamente no bucket do S3. Esse ciclo pode ser repetido para criar novas imagens de forma contínua e eficiente.

As ferramentas da AWS empregadas nesses dois casos desempenham papéis essenciais para a construção das soluções apresentadas:
- **Amazon API Gateway**: Serviço gerenciado que facilita a criação, publicação, monitoramento e proteção de APIs REST. Ele permite a conexão segura entre sistemas finais e a infraestrutura de back-end, garantindo que os eventos e dados sejam transmitidos de forma eficiente e escalável.
- **AWS Lambda:** Serviço de computação serverless e orientado a eventos que executa código sem a necessidade de provisionamento ou gerenciamento de servidores. Ele responde automaticamente aos eventos gerados pelo API Gateway, processando prompts e realizando inferências em tempo real, tornando a arquitetura mais ágil e eficiente.
- **Amazon Bedrock:** Plataforma totalmente gerenciada que oferece uma gama de modelos de base (Foundations Models - FMs) de alto desempenho, desenvolvidos por líderes do setor de IA. Bedrock permite acessar e utilizar esses modelos de forma simplificada, facilitando a criação de soluções de IA generativa para diversas finalidades, desde geração de texto até imagens e código.
- **Amazon Simple Storage Service (Amazon S3)**: Serviço escalável e altamente disponível para armazenamento de objetos, utilizado para guardar e acessar os arquivos gerados, como as imagens criadas nos processos de mídia e entretenimento. O S3 garante que os dados estejam sempre acessíveis e seguros, facilitando a entrega rápida dos conteúdos ao usuário final por meio de URLs públicas ou privadas.

<a name="item2.2"><h4>2.2 Mentoria: Dominando IA Generativa com Claude 3 no Amazon Bedrock</h4></a>[Back to summary](#item2) | <a href="https://github.com/PedroHeeger/main/blob/main/cert_ti/04-curso/ai/(24-08-12)_DP-Natural...Fake_Natty...IAs_Generativas_PH_DIO.pdf">Certificate</a>










<a name="item2.3"><h4>2.3 Mentoria: Amazon Q: IA Generatica como Copiloto de Programação Python</h4></a>[Back to summary](#item2) | <a href="https://github.com/PedroHeeger/main/blob/main/cert_ti/04-curso/ai/(24-08-12)_Visao_Computacional_PH_DIO.pdf">Certificate</a>











<a name="item2.5"><h4>2.5 Desafio de Código: Treinando Desafios de Códigos com IAs Generativas</h4></a>[Back to summary](#item2)

Neste trio de desafios de código, o primeiro desafio, cujo nome foi [geracao_conteudo.py](./05-dc/geracao_conteudo.py), consistiu em identificar qual dos modelos **Claude 3** da **Anthropic** seria utilizado a partir de uma descrição enviada como entrada pelo usuário. Cada modelo tinha uma descrição correspondente. Para executar isso, uma função foi criada que recebia como parâmetro as descrições de entrada do usuário. Em seguida, uma iteração era realizada em um dicionário que armazenava todos os modelos com suas respectivas características, percorrendo cada modelo e com uma estrutura de condição era verificado se a descrição desses modelos era igual a descrição enviada como entrada pelo usuário. Caso fosse, retornava o modelo correspondente. Se não fosse, retornava a mensagem "Modelo não encontrado". Por fim, o valor retornado da função era armazenado em uma variável e em seguida printado na tela.

O segundo desafio, intitulado de [melhor_modelo_ia.py](./05-dc/melhor_modelo_ia.py), teve como objetivo identificar o melhor modelo **Claude 3** da **Anthropic** a partir de dados de entrada do usuário. Cada entrada do usuário consistia em quatro linhas, sendo as três primeiras um número inteiro que definia o desempenho, velocidade e custo do modelo, e a última linha uma lista de capacidades específicas do modelo separadas por vírgulas. Esses dados eram inseridos através da função `obter_caracteristicas` que após inserir as quatro informações, os dados eram retornados sendo armazenado na variável `caracteristicas_entrada`. Essa variável era utilizada na sequência com atributo de uma outra função, essa de nome `recomendar_modelo`. Essa função recebia as informações que foram dadas como entrada pelo usuário e comparava com uma lista de objetos de um classe criada de nome `ModeloIA`. Essa classe tinha os seguintes atributos: `nome`, `desempenho`, `velocidade`, `custo` e `capacidades`. Basicamente, todas as informações enviadas pelo usuário, exceto o nome do modelo. As informações do modelo procurado pelo usuário era comparada com a da lista de objetos, que possuía três objetos, cujo atributo nome de cada era: `Claude 3 Sonnet`, `Claude 3 Haiku` e `Claude 3 Opus`. Essa comparação era realizada através de iterador `for` que pecorria a lista de objetos, extraindo as informações de capacidade e comparado com as procuradas pelo usuário. Se fosse igual, o modelo que tivesse o maior desempenho era retornado. Caso as informações de capacidade fossem divergentes, a mensagem "Nenhum modelo encontrado." era exibida. O modelo retornado era armazenado em outra variável (`melhor_modelo`) e essa era passada como atributo para uma terceira função dessa classe (`gerar_explicacao`). Essa função ainda recebia as características passada pelo usuário através da função `obter_caracteristicas`, mas não utilizava. O foco da função `gerar_explicacao` era verificar se o modelo retornado era uma instância, ou seja, um objeto da classe `ModeloIA`, se fosse, uma explicação com o nome do modelo eram retornado, armazenado em outra variável e impresso.

O último desafio de código desse trio foi o [modelo_amazon_bedrock.py](./05-dc/modelo_amazon_bedrock.py). O propósito foi o mesmo dos outros dois, identificar o melhor modelo, sendo neste caso, escolhido com base no orçamento, priorizando modelos com preço mais próximo ao orçamento fornecido pelo usuário. O usuário fornecia como entrada apenas um número inteiro que era o valor do orçamento. Essa valor era passado para uma função junto com uma lista de dicionários contendo os três modelos do **Claude 3** da **Anthropic**, que são disponíveis no **Amazon Bedrock**. Dentro da função, o orçamento era verificado se era menor que 250, pois era o valor mínimo para escolher um modelo. Caso não fosse, retornava a mensagem "Seu orçamento é muito baixo para recomendar um modelo adequado.". Se fosse maior que 250, eram verificados na lista de modelos quais modelos possuía o valor menor que o valor informado pelo usuário, e eram armazenados em uma outra lista. Mesmo se nenhum modelo fosse armazenado nessa lista, era verificado qual modelo possuía o valor mais próximo do orçamento e este era retornado. Se todos os modelos estivessem dentro do orçamento, a decisão era pela maior pontuação de desempenho, retornando assim, o nome do modelo. Em ambos os casos, além do nome do modelo, era retornado também uma explicação do porque da escolha desse modelo. Essas duas informações eram exibidas no terminal.