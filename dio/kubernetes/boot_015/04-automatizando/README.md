# Formação Kubernetes Fundamentals - Módulo 4   <img src="../0-aux/logo_boot.png" alt="boot_015" width="auto" height="45">

### Repository: [boot](../../../../)   
### Platform: <a href="../../../">dio   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/plataforma/dio.jpeg" alt="dio" width="auto" height="25"></a>   
### Software/Subject: <a href="../../">kubernetes   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/kubernetes/kubernetes-plain.svg" alt="kubernetes" width="auto" height="25"></a>
### Bootcamp: <a href="../">boot_015 (Formação Kubernetes Fundamentals)   <img src="../0-aux/logo_boot.png" alt="boot_015" width="auto" height="25"></a>
### Module: 4. Automatizando Deployments com Kubernetes 

---

This folder refers to Module 4 **Automatizando Deployments com Kubernetes** from bootcamp [**Formação Kubernetes Fundamentals**](../).

### Theme:
- DevOps
- Distributed Computing

### Used Tools:
- Operating System (OS): 
  - Linux   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/linux/linux-original.svg" alt="linux" width="auto" height="25">
  - Windows 11   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/windows11.png" alt="windows11" width="auto" height="25">
- Linux Distribution:
  - Ubuntu   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/ubuntu/ubuntu-plain.svg" alt="ubuntu" width="auto" height="25">
- Virtualization: 
  - Oracle VM VirtualBox   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/vm_virtualbox.png" alt="vm_virtualbox" width="auto" height="25">
- Cloud Services:
  - Amazon Elastic Compute Cloud (EC2)   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/cloud/aws_ec2.svg" alt="aws_ec2" width="auto" height="25">
  - Google Drive <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/google_drive.png" alt="google_drive" width="auto" height="25">
- Containerization: 
  - Docker   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/docker/docker-original.svg" alt="docker" width="auto" height="25">
- Cluster Management Software:
  - Kubernetes   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/kubernetes/kubernetes-plain.svg" alt="kubernetes" width="auto" height="25">
  - MiniKube   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/minikube.jpg" alt="minikube" width="auto" height="25">
- Language:
  - HTML   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/html5/html5-original.svg" alt="html" width="auto" height="25">
  - Markdown   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/markdown/markdown-original.svg" alt="markdown" width="auto" height="25">
  - YAML   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/yaml.png" alt="yaml" width="auto" height="25">
- Integrated Development Environment (IDE) and Text Editor:
  - Nano   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/nano.png" alt="nano" width="auto" height="25">
  - Vi   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/vi.png" alt="vi" width="auto" height="25">
  - VI iMproved (Vim)   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/vim/vim-original.svg" alt="vim" width="auto" height="25">
  - Visual Studio Code (VS Code)   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/vscode/vscode-original.svg" alt="vscode" width="auto" height="25">
- Versioning: 
  - Git   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/git/git-original.svg" alt="git" width="auto" height="25">
- Repository:
  - GitHub   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/github/github-original.svg" alt="github" width="auto" height="25">
- Command Line Interpreter (CLI):
  - AWS Command Line Interface (CLI)   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/cloud/aws_cli.svg" alt="aws_cli" width="auto" height="25">
  - Bash e Sh   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/bash/bash-original.svg" alt="bash_sh" width="auto" height="25">
  - Kubectl   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/kubernetes/kubernetes-plain.svg" alt="kubernetes" width="auto" height="25">
  - Oh My Zshell (Oh My ZSh)   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/oh_my_zshell.png" alt="oh_my_zshell" width="auto" height="25">
  - ZShell   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/zshell.png" alt="zshell" width="auto" height="25">
- Server and Databases:
  - Apache HTTP Server (httpd)   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/apache_http_server.png" alt="apache_httpd" width="auto" height="25">
  - MySQL Server   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/mysql/mysql-original.svg" alt="mysql_server" width="auto" height="25">
- Database Administration Tool:
  - DBeaver   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/dbeaver.png" alt="dbeaver" width="auto" height="25">
- Tools:
  - Advanced Package Tool (Apt)   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/apt.png" alt="apt" width="auto" height="25">
  - Advanced Package Tool (Apt-Get)   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/apt-get.jpg" alt="apt-get" width="auto" height="25">
  - Curl   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/curl.png" alt="curl" width="auto" height="25">
  - Wget   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/wget.webp" alt="wget" width="auto" height="25">
- Development:
  - GitLab   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/gitlab/gitlab-original.svg" alt="gitlab" width="auto" height="25">

---

### Bootcamp Module 4 Structure
4. <a name="item4">Automatizando Deployments com Kubernetes</a><br>
  4.1. <a href="#item4.1">Deployment e Roolback em Clusters Kubernetes</a><br>
  4.2. <a href="#item4.2">CI-CD Utilizando Kubernetes</a><br>
  4.3. <a href="#item4.3">Criando um Pipeline de Deploy com GitLab e Kubernetes</a><br>
  4.4. Materiais Complementares: Arquitetura e Deploy de Microsserviços  

---

### Objective:
O objetivo deste módulo do bootcamp foi mostrar como realizar o processo de roolback entre as implantações realizadas e como criar e utilizar o objeto *Secret*. Também foi explicado os conceitos de *Continuous Integration (CI)* e *Continuous Delivery (CD)* que são práticas de desenvolvimento de software bastante utilizadas para acelerar o processo de deploy de um software com alta qualidade.

### Structure:
A estrutura das pastas obedeceu a estruturação do bootcamp, ou seja, conforme foi necessário, sub-pastas foram criadas para os cursos específicos deste módulo. Na imagem 01 é exibida a estruturação das pastas. 

<div align="Center"><figure>
    <img src="../0-aux/md4-img01.png" alt="img01"><br>
    <figcaption>Imagem 01.</figcaption>
</figure></div><br>

### Development:
O desenvolvimento deste módulo do Bootcamp foi dividido em dois cursos. Abaixo é explicado o que foi desenvolvido em cada uma dessas atividades.

<a name="item4.1"><h4>4.1 Deployment e Roolback em Clusters Kubernetes</h4></a>[Back to summary](#item4) | <a href="https://github.com/PedroHeeger/main/blob/main/cert_ti/04-curso/distributed_computing/kubernetes/(24-02-19)_Deployment...Roolback_PH_DIO.pdf">Certificate</a>

No primeiro curso do último módulo, foi explicado sobre o roolback que é quando um deployment implantado em uma versão mais nova precisa voltar para versão anterior. Para que isso ocorresse, ao implantar o deployment ou qualquer outro objeto **Kubernetes** era necessário registrar o comando de implantação. A pasta [rollout](./rollout/) foi construída na instância do EC2 e dentro dela o arquivo [deploy.yml](./rollout/deploy.yml) foi elaborado para exemplificar esta situação. Este arquivo criou um deployment com 3 réplicas, cujo nome dele, da label, do seletor, da label do template e do container foi `httpd`. A imagem utilizada foi a `httpd:2` e a porta onde seria executada o servidor web **Apache HTTP (Httpd)** era a `80`. No diretório do arquivo, com o comando `kubectl apply -f deploy.yml --record` foi utilizado o parâmetro `--record` que registrava os comandos em um histórico.
A visualização desse histórico foi realizada com execução do comando `kubectl rollout history deployment httpd`, conforme imagem 02.

<div align="Center"><figure>
    <img src="../0-aux/md4-img02.png" alt="img02"><br>
    <figcaption>Imagem 02.</figcaption>
</figure></div><br>

Após isso, o mesmo arquivo de deployment foi modificado, alterando a imagem do container para `httpd:latest` e novamente com o comando `kubectl apply -f deploy.yml --record` essa nova implantação foi realizada. Ao consultar o histórico com o comando `kubectl rollout history deployment httpd`, agora existiam dois registros, o primeiro na versão 2 e o segundo na versão `latest` que era a que estava implantada no momento. Novamente, o arquivo de deployment foi alterado, modificando a imagem agora para `httpd:errado` que era uma imagem que não existe, só para provocar o erro. Ao consultar o histórico, conforme imagem 03, agora existem três registros, sendo o terceiro em execução que era o que possuía a imagem incorreta.

<div align="Center"><figure>
    <img src="../0-aux/md4-img03.png" alt="img03"><br>
    <figcaption>Imagem 03.</figcaption>
</figure></div><br>

Com esse histórico foi possível aproveitá-lo para executar o roolback que era justamente voltar para a revisão 2 cujo a imagem era a `latest`. Então foi utilizado o comando `kubectl rollout undo deploy.yml` e com o comando `kubectl describe httpd` foi possível verificar que a imagem utilizada era agora a `latest`, evidenciado na imagem 04.

<div align="Center"><figure>
    <img src="../0-aux/md4-img04.png" alt="img04"><br>
    <figcaption>Imagem 04.</figcaption>
</figure></div><br>

No histórico a revisão utilizada era a 3 que tinha a imagem `errada`, quando o roolback foi realizado, retornou para revisão 2, cuja imagem era `latest`, e essa revisão 2 passou a ser a revisão 4, não existindo mais a revisão 2. Isso é mostrado na imagem 05 a seguir. Caso fosse executado novamente o comando de roolback, a revisão iria de 4 para 3, ou seja, a imagem do container alteraria de `latest` para `errada`.

<div align="Center"><figure>
    <img src="../0-aux/md4-img05.png" alt="img05"><br>
    <figcaption>Imagem 05.</figcaption>
</figure></div><br>

Com o comando `kubectl rollout undo deployment_name --to-revision=1` agora era definido para qual revisão deveria ser retornado ao realizar o roolback. Logo a revisão 1, cuja imagem era `2`, tornou-se revision 5, e a 1 não existia mais. A imagem 06 mostra o histórico de revisões. Enquanto a imagem 07 exibe a imagem do container na revisão atual do deployment. 

<div align="Center"><figure>
    <img src="../0-aux/md4-img06.png" alt="img06"><br>
    <figcaption>Imagem 06.</figcaption>
</figure></div><br>

<div align="Center"><figure>
    <img src="../0-aux/md4-img07.png" alt="img07"><br>
    <figcaption>Imagem 07.</figcaption>
</figure></div><br>

Em todo esse processo, na verdade, o deployment era o mesmo, o que modificava era o replicaset. O replicaset garante que um número específico de réplicas de pod esteja em execução a qualquer momento. Então o que era alterado era o replicaset e cada replicaset tinha seus pods com containers utilizando a imagem determinada.

Para melhor organização com relação ao arquivo de manifesto **YAML** é indicado utilizar um número determinando a revisão, por exemplo `app-html1.0.yml`. Assim quando for listado no histórico os comandos executados, cada arquivo vai ter seu nome com um número de revisão que facilitará a identificação. Nesse caso, seria necessário criar cada arquivo individualmente com suas modificações, mesmo que mínimas. Na imagem 08 é mostrado o histórico com os nomes de arquivos com suas respectivas revisões.

<div align="Center"><figure>
    <img src="../0-aux/md4-img08.png" alt="img08"><br>
    <figcaption>Imagem 08.</figcaption>
</figure></div><br>

Nessa próxima etapa foi abordado sobre a *Secret*, que é um objeto do **Kubernetes** que contém uma pequena quantidade de informação sensível, como senhas, tokens ou chaves. Este tipo de informação poderia, em outras circunstâncias, ser colocada diretamente em uma configuração de Pod ou em uma imagem de container. O uso de Secrets evita que seja incluído dados confidenciais no código. Secrets podem ser criados de forma independente dos Pods que os consomem. Isto reduz o risco de que o Secret e seus dados sejam expostos durante o processo de criação, visualização e edição ou atualização de Pods.

Um novo arquivo de manifesto **YAML** de nome [secrets.yml](./rollout/secrets.yml) foi elaborado dentro da pasta `rollout`. Este construíu um objeto secret de nome `my-secret`, definindo o tipo `Opaque` e em `data` um par chave e valor de uma variável de ambiente e seu valor. Nesse caso, foram criadas as variáveis `ROOT_PASSWORD` e `MYSQL_DATABASE` que seria informadas no arquivo de deployment do banco de dados. Com o comando `kubectl apply -f secrets.yml`, o objeto secrets foi implantado e foi exibido com o comando `kubectl get secret`, conforme imagem 09.

<div align="Center"><figure>
    <img src="../0-aux/md4-img09.png" alt="img09"><br>
    <figcaption>Imagem 09.</figcaption>
</figure></div><br>

Com o secret implatando, um arquivo de deployment de banco de dados **MySQL Server** foi desenvolvido. O nome desse arquivo foi [mysql.yml](./rollout/mysql.yml) e o nome do deployment foi `mysql-deployment`. A label, o seletor, a label do template e o nome do container foram definidos como `mysql`. O número de réplicas foi de apenas `1`, a imagem utilizada no container foi `mysql:5:7` e a porta foi a padrão do MySQL (`3306`). A grande mudança foi na forma como as variáveis de ambientes eram definidas, agora com utilização das secrets sem passar informações sensíveis direto no código. Utilizando o comando `kubectl describe pod pod_name`, perceba que as variáveis não estão referenciadas no pod, conforme comprovado na imagem 10 abaixo.

<div align="Center"><figure>
    <img src="../0-aux/md4-img10.png" alt="img10"><br>
    <figcaption>Imagem 10.</figcaption>
</figure></div><br>

<a name="item4.2"><h4>4.2 CI-CD Utilizando Kubernetes</h4></a>[Back to summary](#item4) | <a href="https://github.com/PedroHeeger/main/blob/main/cert_ti/04-curso/distributed_computing/kubernetes/(24-02-20)_CI-CD...Kubernetes_PH_DIO.pdf">Certificate</a>

A implantação (Deploy) envolve mover o software de um ambiente controlado para outro. Um ambiente é um subconjunto de infraestrutura de TI usado para uma finalidade específica. Com o objetivo de aprimorar e agilizar os processos de deploy, existem práticas de desenvolvimento de software muito utilizadas na metodologia *DevOps*. O *DevOps* é uma metodologia de desenvolvimento de software mais atual que envolve a colaboração entre os desenvolvedores de software e as equipes de operações de infraestrutura, garantindo que as mudanças de software possam ser implantadas de forma segura e eficiente em ambientes de produção. 

O *DevOps* utiliza práticas de desenvolvimento de software como *Continuous Integration (CI)* e *Continuous Delivery (CD)*. A integração contínua é uma prática de desenvolvimento de software em que os desenvolvedores, com frequência, juntam suas alterações de código em um repositório central. Depois disso, criações e testes são executados. Os principais objetivos da integração contínua são encontrar e investigar erros mais rapidamente, melhorar a qualidade do software e reduzir o tempo necessário para validar e lançar novas atualizações de software. Já a entrega contínua é uma prática de desenvolvimento de software em que alterações de código são criadas, testadas e preparadas automaticamente para liberação para produção. Ela expande com base na integração contínua, pela implantação de todas as alterações de código em um ambiente de teste e/ou ambiente de produção, após o estágio de criação. Quando a integração contínua for implementada adequadamente, os desenvolvedores sempre terão um artefato de criação pronto para ser implantado, e que passou por um processo de teste padronizado.

Nesse curso foi apresentada a plataforma **GitLab** que é um gerenciador de repositório de software baseado em **Git**, com suporte a Wiki, gerenciamento de tarefas e CI/CD. **GitLab** é similar ao **GitHub**, mas o **GitLab** permite que os desenvolvedores armazenem o código em seus próprios servidores, ao invés de servidores de terceiros. Como ainda não tinha cadastro nessa plataforma, foi necessário criar um. Também foi preciso criar um *Personal Access Tokens (PAT)* para ser utilizado ao credenciar o **Git** de uma maquina nesta conta do **GitLab**. Para fazer isso foi escolhida a opção `Search or go to...`, que é a lupa, e então uma caixa foi aberta e foi clicada na opção `profile`. Assim a barra lateral alterou para o `User Settings` e então apareceu a opção `Access Tokens` que foi escolhida. Dentro do PAT, foi clicada na opção `Add new Token`, um nome foi definido para esse token e as permissões que ele teria, que no caso foram todas, a data foi mantida em branco, logo foi definido um prazo de 1 ano para expiração. O segredo do token foi copiado e armazenado, era com ele que seria feito o login do **Git** da maquina utilizada no **GitLab**.

Após o cadastro e a criação do token, foi desenvolvido um projeto cujo nome foi `boot015_app-cicd`, o nível de visibilidade foi público e já ele já foi iniciado com um arquivo de README. A instância do EC2, onde o cluster do **MiniKube** era executada já vinha com o software **Git** instalado. Então com o comando `git config --global user.email "seu email"` e `git config --global user.name "Pedro Heeger"` foi definido o nome e email do usuário que estaria executando os comandos Git nesta maquina. Em seguida, o diretório [cicd](./cicd/) foi criado na pasta do usuário na instância. Dentro deste diretório, a sub-pasta [app](./cicd/app/) foi construída e dentro dela, o arquivo [index.html](./cicd/app/index.html) foi elaborado apenas colocando no título e no body a frase `App 1.0` para representar a aplicação na versão 1.0.

Para indicar que a pasta criada seria um repositório, dentro dela foi preciso executar o comando `git init --initial-branch=main`. Em seguida com o comando `git remote add origin https://gitlab.com/pedroheeger1/boot015_app-cicd.git` foi vinculado o repositório local (a pasta) com o repositório remoto no **GitLab**. Eram os mesmos comandos utilizados com o **GitHub**. Para fazer o primeiro push foi executado o comando `git add .` para adicionar os arquivos, no caso o arquivo `index.html` à área de stagging, depois o comando `git commit -m "Commit inicial"` para commitar essa alteração e então enviá-la com o comando `git push --set-upstream origin main`. A imagem 11 mostra o arquivo já no repositório do **GitLab**.

<div align="Center"><figure>
    <img src="../0-aux/md4-img11.png" alt="img11"><br>
    <figcaption>Imagem 11.</figcaption>
</figure></div><br>

Dentro do diretório `app` foi elaborado o arquivo [dockerfile](./cicd/app/dockerfile) para construção da imagem **Docker** da aplicação. Este arquivo utilizou como imagem base a do servidor web **Apache HTTP (Httpd)** (`httpd:latest`), definiu como diretório de trabalho a pasta padrão do Httpd (`/usr/local/apache2/htdocs/`), copiou o arquivo `index.html` para dentro dela e definiu a exposição da aplicação na porta `80`. Até essa parte, era basicamente o que vinha sendo feito nos cursos anteriores.

Voltando para o diretório `cicd`, foi criado o arquivo CI do **GitLab**, cujo nome era [.gitlab-ci.yml](./cicd/.gitlab-ci.yml), sendo ele um arquivo **YAML**. Antes de explicar sobre o arquivo, no **GitLab**, na opção `Settings`, `CI/CD`, em `Variables` foram cadastradas as variáveis de ambiente `DOCKERHUB_USER` e `DOCKERHUB_PASSWORD` para conexão do **GitLab** a minha conta do **Docker Hub**. Na variável `DOCKERHUB_PASSWORD` foi cadastrado o secret access key ao invés da senha, pois no **Docker Hub** já possuía a access key de nome `Access_PH_GitHub` destinada para o **GitHub** que foi aproveitada para o **GitLab**. A flag `Protect variable` foi mantida marcada, o `Type` foi `Variable (default)` e `Environments` foi `All (default)`.

Com relação ao arquivo, dois stages foram desenvolvidos. O primeiro stage foi o build que realizou o build e o push da imagem `pedroheeger/boot015_app-cicd:1.0`. Mas para conseguir fazer o build da imagem, esse stage precisou da imagem `docker:20.10.16`, que é uma imagem do **Docker**, e o `service` desse stage utilizou a imagem `docker:20.10.16-dind` que é o daemon do **Docker**. Em `variables` foi preciso especificar onde seria gerado os certificados do **Docker**, então utilizou-se `DOCKER_TLS_CERTDIR: "/certs"`. Antes de executar o script que faria o build e o push, era necessário logar na conta do **Docker Hub** e isso foi realizado em `before_script` com o comando `docker login -u $DOCKERHUB_USER -p $DOCKERHUB_PASSWORD`, justamente passando as variáveis criadas no **GitLab**. Assim, era evitado compartilhar dados sensíveis no arquivo.

Um novo envio para o repositório remoto no **GitLab** foi realizado com os comandos `git add`, `git commit` e `git push`. Dessa forma, o pipeline de CI era iniciado pelo **GitLab** e pôde ser visualizado na opção `Build` em `Pipelines`, conforme mostrado na imagem 12 abaixo.

<div align="Center"><figure>
    <img src="../0-aux/md4-img12.png" alt="img12"><br>
    <figcaption>Imagem 12.</figcaption>
</figure></div><br>

Para o segundo stage era necessário o arquivo de deployment, cujo nome foi [deployment.yml](./cicd/deployment.yml). Neste arquivo foi construído um deployment, no qual o nome dele, da sua label, do seletor, da label do template e do container foi `app`. A imagem utilizada foi a enviada para o repositório no **Docker Hub**, `pedroheeger/boot015_app-cicd:1.0` e a porta onde a aplicação rodaria no container foi definida como `80`. Um service do tipo node port também foi desenvolvido, sendo seu nome igual a `app-service`. Um seletor foi definido apontando para o nome do pod do deployment (`app`) e na configuração de porta, a porta `80` foi definida para o service e para o alvo nos containers dos pods e a node port foi determinada em `30005`.

No segundo stage foram passados alguns comandos na opção `script` para serem executados. O primeiro deles era o `kubectl config use-context minikube` para configurar o **Kubectl** da instância do EC2 com o cluster criado no **MiniKube**. Depois foi executado o comando `kubectl apply -f deployment.yml` para implantar o deployment e seu service. Ao enviar todos os arquivos para o repositório remoto, o pipeline de CI era iniciado primeiro, logo em seguida o de CD era executado implantando o projeto no cluster. Na imagem 13 abaixo foi acessada a aplicação no navegador da maquina física.

<div align="Center"><figure>
    <img src="../0-aux/md4-img13.png" alt="img13"><br>
    <figcaption>Imagem 13.</figcaption>
</figure></div><br>

Após isso, foi realizado uma alteração no arquivo `index.html` modificando ele para versão 2.0 e enviando novamente para **GitLab**. Todo o processo de build da imagem e deploy da aplicação era realizado pelos pipelines. A imagem 14 exibe a aplicação containerizada na versão 2.0.

<div align="Center"><figure>
    <img src="../0-aux/md4-img14.png" alt="img14"><br>
    <figcaption>Imagem 14.</figcaption>
</figure></div><br>

<a name="item4.3"><h4>4.3 Criando um Pipeline de Deploy com GitLab e Kubernetes</h4></a>[Back to summary](#item4) | <a href="https://github.com/PedroHeeger/main/blob/main/cert_ti/04-curso/distributed_computing/kubernetes/(24-02-20)...Pipeline...Git_Lab...Kubernetes_PH_DIO.pdf">Certificate</a>

Esse segundo desafio de projeto foi igual ao desafio de projeto do módulo três, cuja pasta foi a [k8s-database-exemplo](../03-expondo_conectando/k8s-database-exemplo/), porém algumas alterações foram realizadas. Ao invés de ser dividido em `back-end`, `front-end` e `database`, foi fragmentado em [app](./dp/app/), que englobava o front e back-end, e [mysql](./dp/mysql/) que era praticamente igual ao `database`. 

No `app` as únicas alterações foram a substituição do arquivo `index.php` por [incluir.php](./dp/app/incluir.php) que era basicamente o mesmo só mudava o insert no banco de dados, pois a tabela tinha a coluna de `email` agora, e a coluna de `mensagens` mudou para `comentario`. A outra alteração foi no arquivo [dockerfile](./dp/app/dockerfile), pois agora todos os arquivos eram copiados para a pasta `/var/www/html`. Um ponto importante era verificar se a url do arquivo [js.js](./dp/app/js.js) apontava para o IP da instância do EC2, agora na porta `80` ao invés `30005` e acrescentando ao path o arquivo `/incluir.php` para realizar a inserção na tabela de banco de dados.

Já em `mysql`, ???

Essas duas pastas (`app` e `mysql`) foram armazenadas no diretório [dp](./dp/) e nele foram criados os arquivos de manifesto **YAML** tanto do **GitLab** como do **Kubernetes**. Os arquivos do **Kubernetes** foram aproveitados do desafio anterior, sendo eles [deployment.yml](./dp/deployment.yml) e [service.yml](./dp/service.yml). No deployment, as alterações foram na imagem do deployment de banco de dados, modificando para `mysql:latest`, tirando o `args` do container do banco de dados e inserindo as variáveis de ambiente por meio de secrets. Também foi alterado os nomes do deployment da aplicação de `php` para `app` e a imagem do container para `pedroheeger/boot015_dp-app:1.0` que foi a imagem construída pelo pipeline de CI. 

No arquivo de service foi exatamente ao desenvolvido no desafio de projeto do módulo 3. O professor, tanto aqui como no módulo 3, utilizou um service do tipo load balancer, pois a execução dele era no **Google Kubernetes Engine (GKE)**. Como no meu caso, a execução era em um cluster do **MiniKube** na instância do EC2, foi utilizado o tipo node port para consegui expor a aplicação ao nó do cluster e acessá-la externamente. Um terceiro arquivo teve que ser criado que foi o [secrects.yml](./dp/secrets.yml) sendo exatamente igual ao desenvolvido no curso 1 deste módulo. Era ele quem iria fornecer os valores das variáveis de banco de dados.

Já o arquivo de pipeline, cujo nome foi [gitlab-ci.yml] foi bastante parecido com do curso 2 deste módulo. Apenas alterando a imagem **Docker** que seria buildada e enviada para o repositório do **Docker Hub** para `pedroheeger/boot015_dp-app:1.0` no stage de build. Enquanto no stage de deploy ao invés de executar só `kubectl apply -f` de um arquivo de manifesto, agora foram três, na seguinte ordem: `secrets`, `deployment` e `service`, registrando no histórico cada comando com o parâmetro `--record`.

