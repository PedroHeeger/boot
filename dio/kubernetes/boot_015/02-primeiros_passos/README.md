# Formação Kubernetes Fundamentals - Módulo 2   <img src="../0-aux/logo_boot.png" alt="boot_015" width="auto" height="45">

### Repository: [boot](../../../../)   
### Platform: <a href="../../../">dio   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/plataforma/dio.jpeg" alt="dio" width="auto" height="25"></a>   
### Software/Subject: <a href="../../">kubernetes   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/kubernetes/kubernetes-plain.svg" alt="kubernetes" width="auto" height="25"></a>
### Bootcamp: <a href="../">boot_015 (Formação Kubernetes Fundamentals)   <img src="../0-aux/logo_boot.png" alt="boot_015" width="auto" height="25"></a>
### Module: 2. Primeiros Passos com o Kubernetes 

---

This folder refers to Module 2 **Primeiros Passos com o Kubernetes** from bootcamp [**Formação Kubernetes Fundamentals**](../).

### Theme:
- DevOps
- Distributed Computing

### Used Tools:
- Operating System (OS): 
  - Linux   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/linux/linux-original.svg" alt="linux" width="auto" height="25">
  - Windows 11   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/windows11.png" alt="windows11" width="auto" height="25">
- Linux Distribution:
  - Ubuntu   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/ubuntu/ubuntu-plain.svg" alt="ubuntu" width="auto" height="25">
- Virtualization: 
  - Oracle VM VirtualBox   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/vm_virtualbox.png" alt="vm_virtualbox" width="auto" height="25">
- Cloud Services:
  - Amazon Elastic Compute Cloud (EC2)   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/cloud/aws_ec2.svg" alt="aws_ec2" width="auto" height="25">
  - Google Drive <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/google_drive.png" alt="google_drive" width="auto" height="25">
- Containerization: 
  - Docker   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/docker/docker-original.svg" alt="docker" width="auto" height="25">
- Cluster Management Software:
  - Kubernetes   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/kubernetes/kubernetes-plain.svg" alt="kubernetes" width="auto" height="25">
  - MiniKube   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/minikube.jpg" alt="minikube" width="auto" height="25">
- Language:
  - HTML   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/html5/html5-original.svg" alt="html" width="auto" height="25">
  - Markdown   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/markdown/markdown-original.svg" alt="markdown" width="auto" height="25">
  - YAML   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/yaml.png" alt="yaml" width="auto" height="25">
- Integrated Development Environment (IDE) and Text Editor:
  - Nano   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/nano.png" alt="nano" width="auto" height="25">
  - Vi   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/vi.png" alt="vi" width="auto" height="25">
  - VI iMproved (Vim)   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/vim/vim-original.svg" alt="vim" width="auto" height="25">
  - Visual Studio Code (VS Code)   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/vscode/vscode-original.svg" alt="vscode" width="auto" height="25">
- Versioning: 
  - Git   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/git/git-original.svg" alt="git" width="auto" height="25">
- Repository:
  - Docker Hub   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/docker_hub.png" alt="docker_hub" width="auto" height="25">
  - Docker Registry   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/docker_registry.png" alt="docker_registry" width="auto" height="25">
  - GitHub   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/github/github-original.svg" alt="github" width="auto" height="25">
- Command Line Interpreter (CLI):
  - AWS Command Line Interface (CLI)   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/cloud/aws_cli.svg" alt="aws_cli" width="auto" height="25">
  - Bash e Sh   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/bash/bash-original.svg" alt="bash_sh" width="auto" height="25">
  - Kubectl   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/kubernetes/kubernetes-plain.svg" alt="kubernetes" width="auto" height="25">
  - Oh My Zshell (Oh My ZSh)   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/oh_my_zshell.png" alt="oh_my_zshell" width="auto" height="25">
  - Windows PowerShell   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/windows_power_shell.png" alt="windows_power_shell" width="auto" height="25">
  - ZShell   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/zshell.png" alt="zshell" width="auto" height="25">
- Server and Databases:
  - Apache HTTP Server (httpd)   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/apache_http_server.png" alt="apache_httpd" width="auto" height="25">
- Tools:
  - Curl   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/curl.png" alt="curl" width="auto" height="25">

---

### Bootcamp Module 2 Structure
2. <a name="item2">Primeiros Passos com o Kubernetes</a><br>
  2.1. <a href="#item2.1">Conceitos Básicos Sobre Pods em Kubernetes</a><br>
  2.2. <a href="#item2.2">Criando Imagens Personalizadas com o Docker</a><br>
  2.3. Materiais Complementares: Primeiros Passos com o Kubernetes  

---

### Objective:
O objetivo deste módulo do bootcamp foi aprender sobre os conceitos de virtualização, container, microsserviços, além dos comandos básicos para se trabalhar com o software **Docker**.

### Structure:
A estrutura das pastas obedeceu a estruturação do bootcamp, ou seja, conforme foi necessário, sub-pastas foram criadas para os cursos específicos deste módulo. Na imagem 01 é exibida a estruturação das pastas. 

<div align="Center"><figure>
    <img src="../0-aux/md1-img01.png" alt="img01"><br>
    <figcaption>Imagem 01.</figcaption>
</figure></div><br>

### Development:
O desenvolvimento deste módulo do Bootcamp foi dividido em dois cursos. Abaixo é explicado o que foi desenvolvido em cada uma dessas atividades.

<a name="item2.1"><h4>2.1 Conceitos Básicos Sobre Pods em Kubernetes</h4></a>[Back to summary](#item2) | <a href="">Certificate</a>

Nesse curso foi aproveitado a instância criada no curso 2 do módulo 1 que possuía o software **MiniKube**, para criar um cluster e executar os arquivos **YAML** desenvolvidos. O **YAML** é uma linguagem de serialização de dados muito usada na escrita de arquivos de configuração. O **YAML**, cujas extensões são .yml ou .yaml, usa um recuo no estilo **Python** para indicar o aninhamento. É necessário utilizar espaços em branco porque os caracteres de tabulação não são permitidos. Não há símbolos de formato comuns, como chaves, colchetes, tags de fechamento ou aspas.

O primeiro arquivo elaborado foi o [simple.pod.yml](./simple.pod.yml), no qual era construído apenas um Pod de nome `app-html` com um container de mesmo nome do Pod. Esse container possuía como imagem **Docker** `httpd:latest`, que é uma imagem do servidor web **Apache HTTP (Httpd)**. Também era indicado que a porta onde a aplicação rodaria no container era a porta `80` que é a porta padrão do Apache HTTP. Para aplicar esse arquivo ao cluster **Kubernetes** foi utilizado o comando `kubectl apply -f simple.pod.yml`. Assim o Pod foi criado no cluster do **MiniKube** da instância EC2, com o container determinado executado a aplicação do servidor web Apache HTTP. Ainda não era possível visualizar a aplicação pelo navegador da web, pois a porta não estava sendo exposta externamente. Na imagem 01 é listado os Pods com o comando `kubectl get pods` (`kubectl get po`). O comando `kubectl get pod -o wide` exibe os pods com mais detalhes, conforme mostrado na imagem 02.

<div align="Center"><figure>
    <img src="../0-aux/md2-img01.png" alt="img01"><br>
    <figcaption>Imagem 01.</figcaption>
</figure></div><br>

<div align="Center"><figure>
    <img src="../0-aux/md2-img02.png" alt="img02"><br>
    <figcaption>Imagem 02.</figcaption>
</figure></div><br>

Como o **MiniKube** criava o cluster construíndo maquinas virtuais no **VirtualBox**, foi possível acessar essas maquinas com o comando `minikube ssh`. Dentro dessa maquina, foi utilizado o software **Curl** para enviar uma requisição ao Pod pelo seu IP e verificar se conseguia obter resposta. O comando executado foi o `curl http://172.17.0.3` e a imagem 03 mostra a obtenção de resposta. Nesse momento, o Pod só possuía comunicação interna, ou seja, dentro do cluster, ainda não era possível acessá-lo externamente.

<div align="Center"><figure>
    <img src="../0-aux/md2-img03.png" alt="img03"><br>
    <figcaption>Imagem 03.</figcaption>
</figure></div><br>

Após isso, esse Pod foi removido com o comando `kubectl delete pod app-html` (`kubectl delete po app-html`) ou utilizando o comando `kubectl delete -f simple.pod.yml`. Em seguida, foi verificado quantos nós existiam no cluster com o comando `kubectl get nodes`, que só possuía um. Com o comando `kubectl describe node minikube` foi mostrado todos os detalhes desse nó, conforme imagem 04.

<div align="Center"><figure>
    <img src="../0-aux/md2-img04.png" alt="img04"><br>
    <figcaption>Imagem 04.</figcaption>
</figure></div><br>

Agora foi criado um novo arquivo de nome [simple-deployment.yml](./simple-deployment.yml) que construía um Deployment. O nome do Deployment foi definido como `app-html-deployment` e uma label de nome `app-html` foi determinada. Nas especificações foi determinada o número de réplicas como 3 e um seletor de labels para encontrar as labels iguais a `app-html`. Dentro de `spec` foi definido um `template` que também possuía a label `app-html` e nas especificações desse template, um container de nome `app-html` era criado também com a imagem `httpd:latest` do servidor web **Apache HTTP (Httpd)** e a porta do container onde a aplicação rodava era a `80`. Com o comando `kubectl apply -f simple-deployment.yml` o Deployment foi desenvolvido no cluster do **MiniKube**. Uma observação aqui, foi que para executar esse comando o diretório corrente tinha que ser onde estava o arquivo, caso contrário, era preciso informar o caminho completo até o arquivo **YAML**. Na imagem 05 a seguir são listados os Pods origniados desse Deployment, que no caso foram três. Já na imagem 06, o comando `kubectl get deployment` (`kubectl get deploy`) para listar os Deployments existentes.

<div align="Center"><figure>
    <img src="../0-aux/md2-img05.png" alt="img05"><br>
    <figcaption>Imagem 05.</figcaption>
</figure></div><br>

<div align="Center"><figure>
    <img src="../0-aux/md2-img06.png" alt="img06"><br>
    <figcaption>Imagem 06.</figcaption>
</figure></div><br>

Com o Deployment, mesmo que um Pod fosse excluído, ele criaria um novo Pod, sempre mantendo as três réplicas estabelecidas. Nesse momento, existiam os Pods no mesmo nó do cluster, porém ainda não existia uma ligação. Era necessário um load balancer para que o **Kubernetes** distribuisse o tráfego de requisições entre os Pods do cluster, equilibrando os Pods. As aplicações nos containers dos Pods ainda não estavam disponíveis para acesso externo, era preciso expor elas externamente. Com o comando `kubectl describe deployment app-html-deployment` foi exibido informações específicas desse Deployment. Já com o comando `kubectl scale deployment app-html-deployment --replicas 5` foi realizada uma alteração do número de réplicas, conforme imagem 07 a seguir.

<div align="Center"><figure>
    <img src="../0-aux/md2-img07.png" alt="img07"><br>
    <figcaption>Imagem 07.</figcaption>
</figure></div><br>

Para expor o Deployment diretamente por comando foi utilizado o `kubectl expose deployment app-html-deployment --type=LoadBalancer --name=app-html --port=80`, no qual foi criado automaticamente um serviço para o load balancer, cujo nome foi `app-html`. Para listar todos os serviços, o comando `kubectl get services` (`kubectl get svc`) foi utilizado, conforme imagem 08. Observe que agora existiam dois serviços, um do próprio **Kubernetes** e outro referente ao load balancer. Este serviço do load balancer possuíu um IP referente ao cluster e um IP externo, sendo este último o que deveria ser utilizado para acessar a aplicação no navegador, utilizando também a porta alocada aleatoriamente. Acontece que como a execução era dentro da instância do EC2, isso não iria funcionar, então para comprovar a resolução, ao invés de acessar pelo navegador da maquina física, foi utilizado o **Curl** na instância para enviar uma requisição e verificar se haveria resposta. Com o comando `curl http://198:32752` foi enviada a requisição e a resposta é exibida na imagem 09. A cada requisição enviada pelo **Curl** da instância EC2 ao nó no cluster ???

<div align="Center"><figure>
    <img src="../0-aux/md2-img08.png" alt="img08"><br>
    <figcaption>Imagem 08.</figcaption>
</figure></div><br>

<div align="Center"><figure>
    <img src="../0-aux/md2-img09.png" alt="img09"><br>
    <figcaption>Imagem 09.</figcaption>
</figure></div><br>

Para remover um Deployment, pôde ser removido pelo arquivo com o comando `kubectl delete -f simple-deployment.yml` ou pelo nome do Deployment `kubectl delete deployment app-html-deployment`

Para visualizar isso, foi acessado o IP público da instância concatenado com `:` e a porta `80` pelo navegador da web da maquina física **Windows**, conforme ilustrado na imagem 01.
Como o **MiniKube** era executado dentro da instância do EC2, foi necessário garantir que a porta `80` no security group estava liberada.

<a name="item2.2"><h4>2.2 Criando Imagens Personalizadas com o Docker</h4></a>[Back to summary](#item2) | <a href=" ">Certificate</a>

Este curso continuo utilizando a instância do EC2 criada na aula 2 do módulo. Duas instalações que eram feita na instância com arquivo user data em **Bash** foram utilizadas dentro dela, que foram os softwares **Docker** e **AWS CLI**. Com o **AWS CLI** foi configurado na instância através do comando `aws configure` o usuário do IAM worker da minha conta da **AWS** (`PedroHeegerWorker`), sendo passadas as credenciais `AWS Access Key Id` e `AWS Secret Access Key`. Para confirmar qual o usuário que a **AWS CLI** da instância estava utilizando foi executado o comando `aws sts get-caller-identity`, conforme mostrado na imagem 10 abaixo. Em seguida, foi executado o comando `docker login` para vincular o **Docker** da instância do EC2 com minha conta no **Docker Hub**, sendo passado o email e o `Secret Acces Key`. Tanto a chave de acesso do **Docker Hub** como da conta **AWS** já estavam configuradas previamente. 

<div align="Center"><figure>
    <img src="../0-aux/md2-img10.png" alt="img10"><br>
    <figcaption>Imagem 10.</figcaption>
</figure></div><br>

<div align="Center"><figure>
    <img src="../0-aux/md2-img11.png" alt="img11"><br>
    <figcaption>Imagem 11.</figcaption>
</figure></div><br>

Dentro da instância, no diretório do usuário foi criada a pasta [app-2.1-kubernetes](./app-kubernetes-1.0/) e nela uma sub-pasta de nome `dockerfile` com os arquivos referente a imagem **Docker** que seria desenvolvida. Dentro da sub-pasta, o primeiro arquivo construído foi o [index.html](./app-kubernetes-1.0/dockerfile/index.html). Em seguida, o arquivo [Dockerfile](./app-kubernetes-1.0/dockerfile/Dockerfile) foi criado. Nele, apenas era indicado que a imagem base seria `httpd:latest` (servidor web **Apache HTTP (httpd)**), que o arquivo `index.html` seria copiado para dentro diretório padrão do Httpd que foi o `/usr/local/apache2/htdocs/`, esse diretório também foi definido como diretório de trabalho, e por fim, a aplicação seria exposta na porta `80`. Com o comando `docker build -t pedroheeger/boot_015-app-html:1.0` foi realizado o build da imagem já com endereço padrão para envio para o **Docker Hub** (repositório de imagens oficial do **Docker**). Assim a imagem foi enviada para o repositório no **Docker Hub** através do comando `docker push pedroheeger/boot_015-app-html:1.0`. A imagem 12 abaixo mostra o repositório criado no **Docker Hub** já com a imagem na tag especificada.

<div align="Center"><figure>
    <img src="../0-aux/md2-img12.png" alt="img12"><br>
    <figcaption>Imagem 12.</figcaption>
</figure></div><br>

Agora foi a vez de criar um novo arquivo de Deployment **YAML**, cujo nome foi [app-deployment.yml](./app-kubernetes-1.0/app-deployment.yml). Basicamente este arquivo foi igual ao o anterior, só aumentando o número de réplicas para `6` e a imagem que foi alterada para a enviada para o **Docker Hub** (`pedroheeger/boot_015-app-html:1.0`). Então, com o comando `kubectl apply -f app-deployment.yml` foi construído este Deployment no cluster do **MiniKube** na instância do EC2. Na imagem 13 a seguir, é evidenciado todos os objetos do cluster **Kubernetes**. Com o comando `kubectl expose deployment app-deployment --type=LoadBalancer --name=app-html --port=80`, a aplicação containerizada foi exposta através de um serviço de load balancer criado. Na imagem 14 é mostrado esse serviço com IP e a porta para acesso a aplicação. Acessa pelo nó (maquina virtual virtua box) ou pela instância do EC2 ?

<div align="Center"><figure>
    <img src="../0-aux/md2-img13.png" alt="img13"><br>
    <figcaption>Imagem 13.</figcaption>
</figure></div><br>

<div align="Center"><figure>
    <img src="../0-aux/md2-img14.png" alt="img14"><br>
    <figcaption>Imagem 14.</figcaption>
</figure></div><br>

Após isso, um novo Deployment foi elaborado, sendo esse uma versão mais atual do anterior. Então foi duplicadaa pasta `app-kubernetes-1.0`, sendo a segunda alterada para [app-2.2-kubernetes](./app-kubernetes-1.1/), alterando o arquivo [index.html](./app-kubernetes-1.1/dockerfile/index.html) e arquivo de Deployment [app-deployment.yml](./app-kubernetes-1.1/app-deployment.yml) para utilizar a imagem mais recente que agora seria `pedroheeger/boot_015-app-html:1.1`. Porém era necessário fazer o build da imagem nessa nova versão e enviar para o repositório no **Docker Hub**. Na imagem 15 é evidenciada a nova tag no repositório no **Docker Hub**. Com o comando `kubectl apply -f` foi indicado o novo arquivo na versão `1.1` para ser implantado ao cluster do **MiniKube** que neste momento ainda estava executando a versão `1.0` da aplicação.

<div align="Center"><figure>
    <img src="../0-aux/md2-img15.png" alt="img15"><br>
    <figcaption>Imagem 15.</figcaption>
</figure></div><br>

O service do load balancer continuava em execução, mesmo com a mudança de versão, sendo visualizado pelo comando `kubectl get services (kubectl get svc)`, conforme imagem 16. Contudo, até agora, tinha sido explicado como expor a porta com o Deployment já implantado, mas foi possível também configurar essa exposição no próprio arquivo **YAML**. Para isso, primeiro foi removido o serviço de load balancer existente com o comando `kubectl delete service app-html`. Em seguida, foi elaborado o arquivo [app-html-lb.yml](app-kubernetes-1.1/app-html-lb.yml) para a construção do serviço de load balancer. Este service teve o nome de `app-html-lb`, sendo configurado um selector com nome do Pod da aplicação `app-html` e uma configuração de porta, no qual primeiro foi informado a porta do container que era a porta `80`, depois a porta que o load balancer iria executar, que também foi a porta `80`, por fim, o tipo de porta que foi `load balancer`. Assim, um ponto já seria resolvido que era a questão da alocação de porta aleatória no load balancer. Na imagem 17 é listado esse novo service.

<div align="Center"><figure>
    <img src="../0-aux/md2-img16.png" alt="img16"><br>
    <figcaption>Imagem 16.</figcaption>
</figure></div><br>

<div align="Center"><figure>
    <img src="../0-aux/md2-img17.png" alt="img17"><br>
    <figcaption>Imagem 17.</figcaption>
</figure></div><br>

Um outro ponto era que até o momento, essa aplicação só era acessada pelo cluster, através dos seus nós. Para que ela fosse de fato acessada externamente, primeiro pela instância do EC2, depois pelo navegador da maquina física era necessário alterar esse tipo de porta para `nodePort`, especificando uma porta no nó que rodaria a aplicação, mas isso foi assunto do curso 3 do terceiro módulo.