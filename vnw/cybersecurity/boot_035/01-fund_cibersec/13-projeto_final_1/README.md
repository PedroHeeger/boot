# Formação Cybersec - Módulo 1 - Projeto Final 1   <img src="../../0-aux/logo_boot.png" alt="boot_035" width="auto" height="45">

### Repository: [boot](../../../../../)   
### Platform: <a href="../../../../">vnw   <img src="https://github.com/PedroHeeger/my_tech_journey/blob/main/platforms/img/vnw.jpeg" alt="vnw" width="auto" height="25"></a>
### Software/Subject: <a href="../../../">cybersecurity   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/content/cybersecurity.jpg" alt="cybersecurity" width="auto" height="25"></a>
### Bootcamp: <a href="../../">boot_035 (Formação Cybersec)   <img src="../../0-aux/logo_boot.png" alt="boot_035" width="auto" height="25"></a>
### Module: 1. Fundamentos de Cibersegurança

---

Esta pasta refere-se ao projeto final opção 1 do módulo 1 **Fundamentos de Cibersegurança** do bootcamp [**Formação Cybersec**](../../). O artefato entregável principal foi o relatório da análise técnica construído no arquivo [relatorio.md](./relatorio.md). Os demais artefáteis entregáveis fizeram parte do projeto e também estão disponíveis nessa pasta e anexados ao relatório.

### Theme:
- Cybersecurity

### Used Tools:
- Operating System (OS): 
  - Linux   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/linux/linux-original.svg" alt="linux" width="auto" height="25">
  - Windows 11   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/windows11.png" alt="windows11" width="auto" height="25">
- Linux Distribution:
  - Ubuntu   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/ubuntu/ubuntu-plain.svg" alt="ubuntu" width="auto" height="25">
- Cloud:
  - AWS   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon@latest/icons/amazonwebservices/amazonwebservices-original-wordmark.svg" alt="aws" width="auto" height="25">
- Cloud Services:
  - Amazon Elastic Compute Cloud (EC2)   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/cloud/aws_ec2.svg" alt="aws_ec2" width="auto" height="25">
  - Google Drive   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/google_drive.png" alt="google_drive" width="auto" height="25">
- Containerization: 
  - Docker   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/docker/docker-original.svg" alt="docker" width="auto" height="25">
  - Docker Compose   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/docker_compose.png" alt="docker_compose" width="auto" height="25">
- Language:
  - HTML   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/html5/html5-original.svg" alt="html" width="auto" height="25">
  - Markdown   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/markdown/markdown-original.svg" alt="markdown" width="auto" height="25">
- Integrated Development Environment (IDE) and Text Editor:
  - Visual Studio Code (VS Code)   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/vscode/vscode-original.svg" alt="vscode" width="auto" height="25">
- Versioning: 
  - Git   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/git/git-original.svg" alt="git" width="auto" height="25">
- Repository:
  - GitHub   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/github/github-original.svg" alt="github" width="auto" height="25">
- Command Line Interpreter (CLI):
  - AWS Command Line Interface (CLI)   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/cloud/aws_cli.svg" alt="aws_cli" width="auto" height="25">
  - Bash e Sh   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/bash/bash-original.svg" alt="bash_sh" width="auto" height="25">
- Tools:
  - Curl   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/curl.png" alt="curl" width="auto" height="25">
- Network:
  - Arp-scan   <img src="" alt="arp-scan" width="auto" height="25">
  - Domain Information Groper (Dig)   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/dig.jpeg" alt="dig" width="auto" height="25">
  - Iproute   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/iproute.png" alt="iproute" width="auto" height="25">
  - Iputils-ping; Iputils   <img src="" alt="iputils" width="auto" height="25">
  - Netdiscover   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/netdiscover.png" alt="netdiscover" width="auto" height="25">
  - Net-tools   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/net-tools.svg" alt="net-tools" width="auto" height="25">
  - Nmap   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/nmap.png" alt="nmap" width="auto" height="25">
  - Ping   <img src="" alt="iputils" width="auto" height="25">
  - Rustscan   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/rustscan.png" alt="rustscan" width="auto" height="25">
- Offensive Security:
  - Kali Linux   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/kali_linux.png" alt="kali_linux" width="auto" height="25">

---

### Bootcamp Module 1 Final Project 1 Structure
1. <a name="item1">Opção 1 – Projeto Técnico: Mapeamento de Rede em Docker<br>
    1.1. <a href="#item1.1">Reconhecimento Técnico da Infraestrutura</a><br>
    1.2. <a href="#item1.2">Análise de Serviços e Exposição de Ativos</a><br>
    1.3. <a href="#item1.3">Avaliação de Riscos e Exposição</a><br>
    1.4. <a href="#item1.4">Inventário Técnico e Classificação dos Ativos de Rede</a><br>
    1.5. <a href="#item1.5">Diagnóstico e Recomendações</a><br>
    1.6. <a href="#item1.6">Documentação Técnica</a><br>

---

### Objective:
O objetivo deste projeto foi aplicar, de forma prática, os conhecimentos adquiridos sobre reconhecimento, varredura de rede e análise de exposição, por meio da investigação de uma rede corporativa simulada em ambiente **Docker**. A proposta consistiu em assumir o papel de um analista de segurança em uma empresa fictícia e conduzir um mapeamento completo dos ativos e sub-redes, elaborando um diagnóstico técnico preciso das exposições encontradas, bem como suas respectivas soluções. Ao final, toda a análise foi consolidada em um relatório técnico estruturado, contendo o inventário dos ativos, o diagrama da rede, os diagnósticos e recomendações das exposições identificadas, além de um plano de ação baseado na estratégia 80/20.

### Folder Structure:
- Este documento de README, escrito em **Markdown**, descreve todo o desenvolvimento do projeto. Embora não seja um artefato entregável, complementa o projeto.
- [relatorio.md](./relatorio.md): Relatório de análise técnica da rede interna da empresa fictícia. É o principal artefato entregável.
- [softwares.md](./softwares.md): Documento em **Markdown** contendo informações relevantes sobre todos os softwares e ferramentas utilizados na análise técnica. É um anexo do relatório técnico.
- [cmds.md](./cmds.md): Documento em **Markdown** com os comandos executados durante a análise técnica. É um anexo do relatório técnico.
- [diagrama.png](./diagrama.png): Arquivo em **PNG** com o diagrama da topologia de rede, construído no **Draw.io**. É um anexo do relatório técnico.
- [outputs](./outputs): Pasta contendo arquivos em **TXT** com os outputs dos comandos executados. É um anexo do relatório técnico.
- [img](./img): Pasta com imagens (prints) dos outputs dos comandos executados. É um anexo do relatório técnico e utilizado neste arquivo de README.

### Development:
Nesta proposta de projeto, foi elaborado um relatório técnico com base na análise realizada de uma rede interna corporativa simulada em ambiente **Docker**. Para sua construção, foi utilizado um modelo em **Markdown** fornecido pela plataforma do curso. Esse modelo contemplava os seguintes itens: sumário executivo, objetivo, escopo, metodologia, diagrama de rede, diagnóstico (achados), recomendações, plano de ação 80/20, conclusão e anexos. Todo o material do projeto, incluindo o modelo de relatório técnico, os documentos de instrução e os arquivos para construção do ambiente, está disponível neste [link](https://github.com/Kensei-CyberSec-Lab/formacao-cybersec/tree/main/modulo1-fundamentos/projeto_final_opcao_1) do GitHub, que é a pasta deste projeto no repositório oficial deste curso da Vai na Web.

A construção do ambiente foi realizada, assim como nos laboratórios do Módulo 1, utilizando o **Docker** em conjunto com o **WSL**. No entanto, optei por utilizar a plataforma **Play With Docker (PWD)** e, nos momentos em que a memória disponível se mostrou insuficiente, recorri a uma instância do **Amazon Elastic Compute Cloud (EC2)**, na nuvem da **Amazon Web Services (AWS)**, como foi o caso deste projeto.

A criação da instância EC2 foi automatizada por meio do script [ec2Instance.ps1](../../environment/ec2Instance.ps1), desenvolvido em **PowerShell** com comandos da **AWS Command Line Interface (CLI)**, localizado na pasta [environment](../../environment/) deste bootcamp. A instância utilizava a imagem `ami-020cba7c55df1f615`, baseada no sistema operacional **Linux Ubuntu**, com um volume **Amazon Elastic Block Store (EBS)** de `8 GB` do tipo `gp` (General Purpose). O tipo instância definido foi `t3.medium` que tem 2vCPU e 4 gigas de memória. O par de chaves utilizado foi o `keyPairUniversal` já existente na minha conta da **AWS**, e o security group associado foi o `default` da zona de disponibilidade `us-east-1a` (Norte da Virgínia). Além disso, foi utilizado um arquivo de user data para automatizar a instalação do **Git** e do **Docker** durante o provisionamento da instância.

A interação com a instância podia ser realizada tanto pelo console da própria **AWS** quanto por meio de conexão SSH utilizando o software **OpenSSH** executado no **Windows PowerShell** da máquina física. Neste último caso, era necessário fornecer o caminho do arquivo de chave privada da chave `keyPairUniversal`, o nome do usuário do sistema operacional que estava logando e o endereço IP ou DNS público da instância, como no exemplo: `ssh -i "G:/Meu Drive/4_PROJ/scripts/aws/.default/secrets/awsKeyPair/universal/keyPairUniversal.pem" ubuntu@54.160.249.118`. Além disso, o **Security Group** associado à instância precisava conter uma regra de entrada liberando a porta `22` para o IP público da máquina física, a fim de permitir o estabelecimento da conexão SSH.

Para a construção do ambiente de laboratório deste projeto, o instrutor do curso disponibilizou, na pasta do repositório do GitHub, um arquivo `docker-compose.yml`. Ao ser executado, esse arquivo cria múltiplos containers e redes virtuais, simulando um ambiente de rede corporativa interna com servidores, estações de trabalho, sub-redes segmentadas e uma máquina de análise. Esse ambiente foi projetado especificamente para o treinamento de habilidades de reconhecimento e análise de exposição em um cenário seguro e controlado. A análise do arquivo `docker-compose.yml` permitiu compreender detalhadamente como o ambiente foi estruturado. Abaixo está um resumo da configuração realizada:
- **Redes Virtuais Criadas:**
  - **`corp_net`**: Rede corporativa principal da empresa, composta por estações de trabalho e um servidor web. CIDR: `10.10.10.0/24`.
  - **`guest_net`**: Rede destinada a visitantes e dispositivos pessoais, isolada da rede corporativa. CIDR: `10.10.50.0/24`.
  - **`infra_net`**: Rede de infraestrutura crítica, responsável por abrigar servidores e serviços internos essenciais. CIDR: `10.10.30.0/24`.
- **Serviços Definidos:**
  - **Estações de trabalho corporativas (`corp_net`):**
    - `WS_001` (10.10.10.10); `WS_002` (10.10.10.101); `WS_003` (10.10.10.127); `WS_004` (10.10.10.222).
    - Todas executando a imagem Ubuntu e configuradas para permanecer ativas com `tail -f /dev/null`.
  - **Estações pessoais (`guest_net`):**
    - `laptop-vastro`; `laptop-luiz`; `macbook-aline`; `notebook-carlos`.
    - Todas utilizando a imagem Ubuntu, simulando computadores pessoais em uma rede separada.
  - **Serviços de infraestrutura (`infra_net`):**
    - `ftp-server`: Servidor FTP usando a imagem `stilliard/pure-ftpd`.
    - `mysql-server`: Banco de dados MySQL com senha root configurada como `root`.
    - `samba-server`: Servidor de arquivos Samba.
    - `openldap`: Servidor de diretório OpenLDAP.
    - `zabbix-server`: Servidor de monitoramento Zabbix Appliance.
    - `legacy-server`: Servidor legado com Ubuntu.
- **Máquina do analista:**
  - `analyst`: Container privilegiado construído a partir de um `Dockerfile` localizado no diretório `./analyst`, com acesso a todas as redes (`corp_net`, `guest_net` e `infra_net`), representando a estação de trabalho do analista de segurança responsável por investigar o ambiente. Esse container foi criado com base em uma imagem do **Kali Linux**, e diversas ferramentas úteis para análise e testes de rede foram instaladas automaticamente, incluindo: **Nmap**, **Rustscan**, **Net-Tools**, **Dig**, **Iproute2**, entre outras. 

Esse ambiente oferecia uma representação próxima de uma rede real corporativa, permitindo simular interações entre dispositivos, vulnerabilidades, acessos indevidos e práticas de análise de segurança. Para executá-lo foi utilizado a instância construída do **Amazon EC2**. Nessa máquina, o repositório da formação completa foi clonado com o comando `git clone https://github.com/Kensei-CyberSec-Lab/formacao-cybersec.git`. Em seguida, foi necessário navegar até a pasta do projeto com o comando `cd formacao-cybersec/modulo1-fundamentos/projeto_final_opcao_1` e executar o comando `docker compose up -d` para iniciar os containers e as redes definidas no arquivo `docker-compose.yml`. Com o comando `docker ps -a`, todos os containers criados (ativos ou inativos) foram listados. Já com o comando `docker network ls`, foi possível visualizar todas as redes construídas. A imagem 01 comprova que o ambiente foi construído com sucesso.

<div align="center"><figure>
    <img src="./img/img01.png" alt="img01"><br>
    <figcaption>Imagem 01.</figcaption>
</figure></div><br>

Como foi identificado tanto no arquivo do **Docker Compose** quanto na imagem 01 acima, a rede interna da empresa estava segmentada em três sub-redes distintas. A máquina de análise utilizada, representada pelo container `analyst`, estava conectada simultaneamente às três redes virtuais, o que lhe permitia acesso irrestrito a todos os segmentos da rede. Por esse motivo, ela não era adequada para realizar testes de isolamento entre as sub-redes. O teste de segmentação de rede foi conduzido a partir de outras máquinas (containers) do ambiente. A partir dessas estações, foram realizadas tentativas de acesso a hosts pertencentes a sub-redes diferentes, com o objetivo de verificar se o isolamento entre os segmentos estava corretamente implementado. Já a máquina de análise (`analyst`) foi utilizada para as demais atividades, como varredura das redes, mapeamento de ativos e análise de exposição de serviços e dispositivos. O acesso ao container `analyst` foi realizado por meio do comando `docker exec -it analyst bash`, o qual abria um shell **Bash** para interação direta via linha de comando (CLI).

#TODO: ESTOU CONCLUÍDO ESSE MATERIAL - PREVISÃO DE FINALIZAÇÃO: 10/08/25

<a name="item1.1"><h4>1.1. Reconhecimento Técnico da Infraestrutura</h4></a> [Back to summary](#item1)

Com o ambiente construído, os primeiros comandos foram executados de dentro do container `analyst` para realizar o reconhecimento inicial. A maioria desses comandos pertencia a ferramentas já instaladas no container, cuja imagem base era o **Kali Linux** — portanto, o sistema operacional utilizado também era o Kali. Os comandos `ip a`, `ip addr` ou `ip address`, pertencentes ao pacote **Iproute2**, juntamente com o comando `ifconfig`, do pacote **Net-tools**, foram os primeiros utilizados, exibindo todas as interfaces de rede às quais o container estava conectado. O comando `ip a | grep inet > recon-redes.txt` foi utilizado para capturar essa saída e armazená-la em um arquivo de texto nomeado [recon-redes](./outputs/recon-redes.txt). As imagens 02 e 03 mostram os outputs desses comandos, que apresentaram os mesmos resultados.

<div align="center"><figure>
    <img src="./img/img02.png" alt="img02"><br>
    <figcaption>Imagem 02.</figcaption>
</figure></div><br>

<div align="center"><figure>
    <img src="./img/img03.png" alt="img03"><br>
    <figcaption>Imagem 03.</figcaption>
</figure></div><br>

Interfaces como `eth0`, `eth1`, entre outras, representam interfaces de rede **Ethernet** — um padrão tecnológico para redes locais (LAN), originalmente voltado a conexões cabeadas (como cabos de par trançado com conector RJ-45), mas que atualmente pode se referir tanto a interfaces físicas quanto virtuais que adotem esse padrão. Já a interface `lo` representa o **loopback**, utilizado para que o próprio sistema se comunique consigo mesmo. Essa interface corresponde ao endereço IP `127.0.0.1`, também conhecido como `localhost`.

Nos outputs, observou-se a presença de uma interface `lo`, correspondente ao loopback, e de três interfaces `eth`, cada uma conectada a uma rede distinta. O CIDR (Classless Inter-Domain Routing) de cada interface indicava redes com a mesma máscara (`/24`) e os dois primeiros octetos iguais, sugerindo que todas pertenciam a uma rede maior. Dessa forma, identificou-se que o CIDR da rede interna da empresa era `10.10.0.0/16`, composta por três sub-redes: `10.10.10.0/24` (`corp_net`), `10.10.30.0/24` (`infra_net`) e `10.10.50.0/24` (`guest_net`). Como mencionado anteriormente, essas sub-redes foram criadas automaticamente pelo **Docker** para simular a topologia do ambiente corporativo. As interfaces do container conectadas a essas redes receberam, respectivamente, os IPs `10.10.10.2`, `10.10.30.2` e `10.10.50.5`.

Com a identificação das sub-redes, o passo seguinte foi testar a comunicação entre elas, verificando se estavam recebendo os pacotes enviados. Para isso, utilizou-se a ferramenta **Ping**, executando os seguintes comandos em cada uma das sub-redes: `ping -c 3 10.10.10.1`, `ping -c 3 10.10.30.1` e `ping -c 3 10.10.50.1`. Os resultados obtidos, conforme a imagem 04, mostraram que todas as três redes estavam comunicáveis.

<div align="center"><figure>
    <img src="./img/img04.png" alt="img04"><br>
    <figcaption>Imagem 04.</figcaption>
</figure></div><br>

Outro comando executado foi o `arp -a`, utilizado da seguinte forma: `arp -a > recon_ip_maps.txt`, onde a saída do comando foi redirecionada para o arquivo [recon_ip_maps.txt](./outputs/recon-ip_maps.txt). Esse comando, que faz parte do pacote **Net-tools**, exibe a tabela ARP, listando os endereços IP e MAC dos hosts que estavam acessíveis em cada sub-rede com a qual o container havia se comunicado. A imagem 05 mostra o output desse comando. Percebe-se que, até este momento, todas as ferramentas utilizadas já estavam disponíveis na máquina `analyst`. Isso ocorreu porque esse container foi construído a partir de um **Dockerfile** que configurou o ambiente com diversos desses softwares previamente instalados.

<div align="center"><figure>
    <img src="./img/img05.png" alt="img05"><br>
    <figcaption>Imagem 05.</figcaption>
</figure></div><br>

De forma semelhante, outras duas ferramentas que inicialmente não estavam instaladas foram adicionadas ao ambiente: **arp-scan** e **netdiscover**, ambas utilizadas para o reconhecimento da rede. Após a instalação, foram executados seis comandos — dois para cada interface de rede. Para a interface `eth0`, utilizarou-se `arp-scan --interface=eth0 --localnet` e `netdiscover -i eth0 -r 10.10.10.0/24`; para `eth1`, `arp-scan --interface=eth1 --localnet` e `netdiscover -i eth1 -r 10.10.30.0/24`; e para `eth2`, `arp-scan --interface=eth2 --localnet` e `netdiscover -i eth2 -r 10.10.50.0/24`. Cada par de comandos retornou os mesmos resultados para sua respectiva interface, identificando todos os hosts ativos e seus respectivos endereços IP dentro da sub-rede analisada. As imagens 06 e 07 apresentam os outputs desses comandos. A partir desses resultados, deu-se início ao mapeamento dos ativos de rede, classificando os hosts e seus IPs por sub-rede.

<div align="center"><figure>
    <img src="./img/img06.png" alt="img06"><br>
    <figcaption>Imagem 06.</figcaption>
</figure></div><br>

<div align="center"><figure>
    <img src="./img/img07.png" alt="img07"><br>
    <figcaption>Imagem 07.</figcaption>
</figure></div><br>

Ainda no processo de varredura de hosts e IPs nas sub-redes, foi utilizado o software **Nmap**, com um par de comandos para cada sub-rede, totalizando seis comandos. Em todos os casos, os resultados foram redirecionados para arquivos `.txt`, conforme ilustrado nas imagens 08 e 09. O primeiro comando de cada par teve como objetivo identificar os IPs ativos nas respectivas sub-redes. Já o segundo comando, além dos IPs, também identificava os nomes dos hosts. Abaixo estão listados os arquivos gerados e os comandos executados:
- Sub-rede `corp_net` (`10.10.10.0/24`):
  - Arquivo: `corp_net_ips.txt` // Comando: `nmap -sn -T4 10.10.10.0/24 -oG - | awk '/Up$/{print $2}' | tee corp_net_ips.txt` 
  - Arquivo: `corp_net_ips_hosts.txt` // Comando: `nmap -sn -T4 10.10.10.0/24 -oG - | awk '/Up$/{print $2, $3}' | tee corp_net_ips_hosts.txt` 
- Sub-rede `infra_net` (`10.10.30.0/24`):
  - Arquivo: `infra_net_ips.txt` // Comando: `nmap -sn -T4 10.10.30.0/24 -oG - | awk '/Up$/{print $2}' | tee infra_net_ips.txt` 
  - Arquivo: `infra_net_ips_hosts.txt` // Comando: `nmap -sn -T4 10.10.30.0/24 -oG - | awk '/Up$/{print $2, $3}' | tee infra_net_ips_hosts.txt` 
- Sub-rede `guest_net` (`10.10.50.0/24`):
  - Arquivo: `guest_net_ips.txt` // Comando: `nmap -sn -T4 10.10.50.0/24 -oG - | awk '/Up$/{print $2}' | tee guest_net_ips.txt` 
  - Arquivo: `guest_net_ips_hosts.txt` // Comando: `nmap -sn -T4 10.10.50.0/24 -oG - | awk '/Up$/{print $2, $3}' | tee guest_net_ips_hosts.txt` 

<div align="center"><figure>
    <img src="./img/img08.png" alt="img08"><br>
    <figcaption>Imagem 08.</figcaption>
</figure></div><br>

<div align="center"><figure>
    <img src="./img/img09.png" alt="img09"><br>
    <figcaption>Imagem 09.</figcaption>
</figure></div><br>

Analisando os outputs, identificou-se que a sub-rede `10.10.10.0` (`corp_net`) possui cinco hosts ativos. A sub-rede `10.10.30.0` (`infra_net`) também apresentou cinco hosts, enquanto a `10.10.50.0` (`guest_net`) revelou sete. Em alguns comandos, como no caso do **Nmap**, o próprio container `analyst` é incluído nos resultados, pois também é um host na rede. Por outro lado, ferramentas como **arp-scan** e **netdiscover** não o listam, uma vez que o comando é executado a partir dele, tornando sua presença implícita. A imagem 10 abaixo mostra apenas a confirmação que esses três softwares e o **Rustscan** foram ou já estavam instalados na máquina de análise.

<div align="center"><figure>
    <img src="./img/img10.png" alt="img10"><br>
    <figcaption>Imagem 10.</figcaption>
</figure></div><br>

<a name="item1.2"><h4>1.2. Análise de Serviços e Exposição de Ativos</h4></a> [Back to summary](#item1)

Até o momento, foi realizado o reconhecimento da rede interna da empresa, com foco em uma abordagem ativa — ou seja, a máquina de análise enviou pacotes diretamente aos alvos. Com isso, foi possível identificar a segmentação da rede e mapear os hosts presentes em cada sub-rede. Também foi executada a varredura de rede (network scanning), que permitiu descobrir os dispositivos ativos. Esses processos forneceram os primeiros dados essenciais para a construção do inventário técnico.

A próxima etapa, abordada nesta seção, consistiu em identificar quais serviços estavam sendo executados nos hosts ativos. A partir disso, foi possível avaliar o grau de exposição desses serviços a potenciais vulnerabilidades. Para identificar os serviços em execução, a abordagem utilizada baseia-se na verificação das portas abertas em cada host. As portas indicam, de forma geral, quais serviços estão ativos e disponíveis. Em situações em que nenhuma porta aberta foi identificada — e, portanto, nenhum serviço pôde ser detectado —, a função presumida do host foi inferida com base em uma análise subjetiva, considerando o nome do host e a sub-rede em que ele estava localizado.

Sendo assim, foram utilizados os softwares **Nmap** e **Rustscan** para identificar os serviços de cada host, as portas abertas e os banners. Um banner é uma mensagem de texto ou informação que um serviço de rede (que está escutando numa porta aberta) envia quando alguém conecta ou faz uma requisição. Geralmente ele contém detalhes sobre o serviço, como: nome do serviço (exemplo: Apache, OpenSSH, Microsoft IIS), versão do software (exemplo: OpenSSH 7.6p1), informações adicionais que podem indicar o sistema operacional ou configurações específicas.

Os comandos foram executados em sequência de três: os dois primeiros para inspeção visual e entendimento geral, e o terceiro para geração de um arquivo de texto contendo os resultados relevantes. A seguir, os comandos utilizados em cada sub-rede:
- Sub-rede `corp_net` (`10.10.10.0/24`):
  - Comando: `nmap -sV -O -Pn 10.10.10.0/24` // Imagem 11
  - Comando: `rustscan -a 'corp_net_ips.txt'` // Imagem 12
  - Comando: `rustscan -a 'corp_net_ips.txt' | grep Open > corp_net_ips_ports.txt` // Arquivo: `corp_net_ips_ports.txt` // Imagem 17
- Sub-rede `infra_net` (`10.10.30.0/24`):
  - Comando: `nmap -sV -O -Pn 10.10.30.0/24` // Imagem 13
  - Comando: `rustscan -a 'infra_net_ips.txt'` // Imagem 14
  - Comando: `rustscan -a 'infra_net_ips.txt' | grep Open > infra_net_ips_ports.txt` // Arquivo: `infra_net_ips_ports.txt` // Imagem 17
- Sub-rede `guest_net` (`10.10.50.0/24`):
  - Comando: `nmap -sV -O -Pn 10.10.50.0/24` // Imagem 15
  - Comando: `rustscan -a 'guest_net_ips.txt'` // Imagem 16
  - Comando: `rustscan -a 'guest_net_ips.txt' | grep Open > guest_net_ips_ports.txt` // Arquivo: `guest_net_ips_ports.txt` // Imagem 17

<div align="center"><figure>
    <img src="./img/img11.png" alt="img11"><br>
    <figcaption>Imagem 11.</figcaption>
</figure></div><br>

<div align="center"><figure>
    <img src="./img/img12.png" alt="img12"><br>
    <figcaption>Imagem 12.</figcaption>
</figure></div><br>

<div align="center"><figure>
    <img src="./img/img13.png" alt="img13"><br>
    <figcaption>Imagem 13.</figcaption>
</figure></div><br>

<div align="center"><figure>
    <img src="./img/img14.png" alt="img14"><br>
    <figcaption>Imagem 14.</figcaption>
</figure></div><br>

<div align="center"><figure>
    <img src="./img/img15.png" alt="img15"><br>
    <figcaption>Imagem 15.</figcaption>
</figure></div><br>

<div align="center"><figure>
    <img src="./img/img16.png" alt="img16"><br>
    <figcaption>Imagem 16.</figcaption>
</figure></div><br>

<div align="center"><figure>
    <img src="./img/img17.png" alt="img17"><br>
    <figcaption>Imagem 17.</figcaption>
</figure></div><br>

Basicamente, o que esses comandos faziam era uma varredura nos IPs dos hosts ativos de cada sub-rede, identificando as portas abertas e trazendo informações adicionais em banner, como qual serviço estava sendo executado, qual sistema operacional do host e versão, entre outros. O último comando criava arquivos de cada sub-rede listando as portas abertas dos hosts e seus respectivos IPs. 

Como visualizado na imagem 17, que exibe o output das três sub-redes, foram identificadas as seguintes portas abertas:
- Sub-rede `corp_net` (`10.10.10.0/24`):
  - IP: `10.10.10.1` // Porta: 22
  - IP: `10.10.10.2` // Porta: 45072
- Sub-rede `infra_net` (`10.10.30.0/24`):
  - IP: `10.10.30.10` // Porta: 21
  - IP: `10.10.30.1` // Porta: 22
  - IP: `10.10.30.117'` // Porta: 80
  - IP: `10.10.30.15` // Porta: 139
  - IP: `10.10.30.17` // Porta: 389
  - IP: `10.10.30.15` // Porta: 445
  - IP: `10.10.30.17` // Porta: 636
  - IP: `10.10.30.11` // Porta: 3306
  - IP: `10.10.30.117` // Porta: 10051
  - IP: `10.10.30.117` // Porta: 10052
  - IP: `10.10.30.11` // Porta: 33060
  - IP: `10.10.30.2` // Porta: 40754
- Sub-rede `guest_net` (`10.10.50.0/24`):
  - IP: `10.10.50.1` // Porta: 22
  - IP: `10.10.50.6` // Porta: 56622

Já havia sido identificado que os IPs `10.10.10.2`, `10.10.30.2` e `10.10.50.6` pertenciam à máquina de análise conectada às respectivas sub-redes. As portas abertas nesses hosts eram portas efêmeras e dinâmicas, sendo utilizadas temporariamente a cada novo scan. Por esse motivo, tais portas foram desconsideradas na análise. 

Também foi identificado que o primeiro IP de cada sub-rede (`10.10.10.1`, `10.10.30.1` e `10.10.50.1`) possuía a porta `22` aberta, correspondente ao protocolo SSH, normalmente utilizado para conexões remotas seguras. Isso indica que esses hosts provavelmente desempenham funções de roteadores, ou atuam como gateways das suas respectivas sub-redes. Para verificar o nível de exposição desses dispositivos, foram realizadas tentativas de conexão SSH a partir do container `analyst`. Em todos os casos, a conexão foi recusada com a mensagem de "Permission denied (publickey)", indicando que a autenticação por chave pública estava configurada e era necessária uma chave privada válida para acesso, conforme mostrado na imagem 18. A autenticação por chave pública é uma prática de segurança recomendada, pois impede o acesso via senha e reduz a superfície de ataque. Por esse motivo, esses hosts foram classificados como de baixa exposição.

<div align="center"><figure>
    <img src="./img/img18.png" alt="img18"><br>
    <figcaption>Imagem 18.</figcaption>
</figure></div><br>

Dessa forma, todos os demais hosts restantes estavam apenas na sub-rede de infraestrutura. Com base nas portas abertas e nas informações dos banners previamente coletadas, foram identificados os seguintes serviços sendo executados:
- Porta 21: Servidor FTP (Transferência de Arquivos)
- Porta 3306: Servidor MySQL (Banco de Dados)
- Porta 389: Servidor LDAP (Autenticação/Consulta de Diretório)
- Porta 636: Servidor LDAPS (LDAP Seguro)
- Portas 139 e 445: Servidor SMB (Compartilhamento de Arquivos/Impressoras)
- Porta 80: Servidor Apache HTTP (Web)
- Portas 10051 e 10052: Servidor Zabbix Proxy e Agent (Monitoramento de Rede)

Um novo scan com o **Nmap** foi realizado em cada porta dessa passando um script padrão do **Nmap** para validar algumas configurações ou obter informações adicionais. Além disso, o software **Curl** também foi utilizado para o servidor web para obter outras informações. Todos esses comandos tiveram seus outputs salvos em arquivos conforme lista abaixo:

Um novo scan com o **Nmap** foi realizado em cada uma dessas portas, utilizando scripts padrão da ferramenta para validar configurações e obter informações adicionais. Além disso, o software **Curl** foi empregado para interagir com o servidor web e coletar outros dados. Todos os comandos tiveram suas saídas salvas em arquivos, conforme a lista abaixo:
- Porta 21: `nmap -p 21 --script ftp-anon 10.10.30.10 > infra_net_servico_ftp-anon.txt` // `infra_net_servico_ftp-anon.txt` // Imagem 19
- Porta 3306: `nmap -p 3306 --script mysql-info 10.10.30.11 > infra_net_servico_mysql-info.txt` // `infra_net_servico_mysql-info.txt` // Imagem 20
- Porta 389: `nmap -p 389 --script ldap-rootdse 10.10.30.17 > infra_net_servico_ldap-rootdse.txt` // `infra_net_servico_ldap-rootdse389.txt` // Imagem 21
- Porta 636: `nmap -p 636 --script ldap-rootdse 10.10.30.17 > infra_net_servico_ldap-rootdse.txt` // `infra_net_servico_ldap-rootdse636.txt` // Imagem 22
- Porta 139: `nmap -p 139 --script smb-os-discovery,smb-enum-shares 10.10.30.15 > infra_net_servico_smb.txt` // `infra_net_servico_smb139.txt` // Imagem 23
- Porta 445: `nmap -p 445 --script smb-os-discovery,smb-enum-shares 10.10.30.15 > infra_net_servico_smb.txt` // `infra_net_servico_smb445.txt` // Imagem 24
- Porta 80: `curl -I http://10.10.30.117 > infra_net_servico_webserver.txt` // `infra_net_servico_webserver.txt` // Imagem 25
- Portas 10051 e 10052: `curl http://10.10.30.117 > infra_net_servico_zabbix.txt` // `infra_net_servico_zabbix.txt` // Imagem 26

<div align="center"><figure>
    <img src="./img/img19.png" alt="img19"><br>
    <figcaption>Imagem 19.</figcaption>
</figure></div><br>

<div align="center"><figure>
    <img src="./img/img20.png" alt="img20"><br>
    <figcaption>Imagem 20.</figcaption>
</figure></div><br>

<div align="center"><figure>
    <img src="./img/img21.png" alt="img21"><br>
    <figcaption>Imagem 21.</figcaption>
</figure></div><br>

<div align="center"><figure>
    <img src="./img/img22.png" alt="img22"><br>
    <figcaption>Imagem 22.</figcaption>
</figure></div><br>

<div align="center"><figure>
    <img src="./img/img23.png" alt="img23"><br>
    <figcaption>Imagem 23.</figcaption>
</figure></div><br>

<div align="center"><figure>
    <img src="./img/img24.png" alt="img24"><br>
    <figcaption>Imagem 24.</figcaption>
</figure></div><br>

<div align="center"><figure>
    <img src="./img/img25.png" alt="img25"><br>
    <figcaption>Imagem 25.</figcaption>
</figure></div><br>

<div align="center"><figure>
    <img src="./img/img26.png" alt="img26"><br>
    <figcaption>Imagem 26.</figcaption>
</figure></div><br>

<a name="item1.3"><h4>1.3. Avaliação de Riscos e Exposição</h4></a>[Back to summary](#item1)

Nesta terceira etapa, os resultados obtidos nos comandos anteriores foram avaliados com o objetivo de verificar o nível de risco e exposição de cada serviço identificado em cada porta dos hosts analisados.

O **Nmap** apontou que o serviço **FTP** estava ativo e escutando na porta 21. O script `ftp-anon`, utilizado para verificar se o servidor permite login anônimo, não retornou informações adicionais, o que indicava que o acesso anônimo poderia estar desabilitado ou que o script não conseguiu obter detalhes relevantes. Para confirmar foi realizada uma tentativa de conexão ao serviço a partir da máquina de análise, conforme imagem 27, contudo, não foi possível identificar a senha de acesso. Apesar disso, é importante destacar que o protocolo **FTP** é considerado inseguro, pois não realiza criptografia dos dados transmitidos. Existe uma versão mais segura, o **SFTP**, que opera sobre **SSH** e garante a criptografia das informações antes da transferência, reduzindo significativamente os riscos de interceptação e vazamento de dados sensíveis.

<div align="center"><figure>
    <img src="./img/img27.png" alt="img27"><br>
    <figcaption>Imagem 27.</figcaption>
</figure></div><br>

O serviço **MySQL**, escutando na porta **3306** do host analisado, foi identificado como ativo. Utilizou-se o script `mysql-info` para obter informações detalhadas sobre o serviço, sendo detectada a versão 8.0.43, com protocolo 10. O script também retornou diversas flags de capacidades do servidor, como suporte a transações, autenticação por plugins e compressão. O método de autenticação configurado é o `caching_sha2_password`, que oferece maior segurança em comparação ao tradicional `mysql_native_password` Entretanto, a exposição dessas informações a clientes não autenticados representa um risco de segurança, pois pode facilitar ações de mapeamento e exploração por parte de atacantes, especialmente no caso de versões com vulnerabilidades conhecidas. O ideal seria restringir a divulgação desses detalhes, permitindo que apenas usuários autenticados tenham acesso a tais informações.

Uma outra vulnerabilidade encontrada foi a possibilidade de estabelecer uma conexão ao banco de dados **MySQL** a partir da máquina de análise utilizando as credenciais padrão `root:root`. Com esse acesso, foi possível criar objetos no banco, conforme imagem 28, o que representa um risco crítico de segurança. Esse tipo de configuração indica uma falha grave na proteção do serviço, permitindo controle total sobre o banco por meio de credenciais fracas e facilmente adivinháveis. Essa exposição pode comprometer completamente os dados e a integridade do sistema.

<div align="center"><figure>
    <img src="./img/img28.png" alt="img28"><br>
    <figcaption>Imagem 28.</figcaption>
</figure></div><br>

O serviço **LDAP**, escutado na porta 389 do host analisado, foi identificado como ativo. Utilizou-se o script `ldap-rootdse` do **Nmap** para coletar informações detalhadas sobre a configuração do servidor **LDAP**. O resultado revelou dados como o contexto de nomes (`namingContexts`), controles e extensões suportadas, versão do protocolo **LDAP** (versão 3) e os mecanismos de autenticação SASL disponíveis, que incluem Kerberos, SCRAM, GSSAPI, NTLM, entre outros. A exposição dessas informações pode representar um risco, pois facilita o reconhecimento da estrutura do diretório e das opções de autenticação, o que pode ser explorado por atacantes para planejar invasões. Além disso, um servidor **LDAP** configurado sem restrições pode permitir consultas não autorizadas, aumentando o risco de vazamento de dados internos. Por isso, recomenda-se restringir o acesso ao servidor **LDAP** apenas a IPs autorizados, implementar autenticação forte para consultas sensíveis, considerar o uso de LDAPS (porta 636) para comunicação criptografada e monitorar eventuais acessos suspeitos para manter a segurança do serviço.

Para verificar a possibilidade de interação com o servidor **LDAP** na porta 389, foi realizada uma tentativa de consulta utilizando o comando `ldapsearch`. A primeira tentativa, buscando todos os objetos a partir da base `dc=example,dc=org`, retornou o erro "No such object", indicando que essa base específica não estava acessível sem autenticação ou que não havia objetos dentro dela. Em seguida, foi feita uma consulta no nível base (`-s base`) solicitando o atributo `namingContexts` a partir do Distinguished Name (Nome Distinto) raiz (`-b ""`). Essa consulta retornou com sucesso o valor `dc=example,dc=org`, confirmando que o servidor está respondendo, conforme imagem 29.

<div align="center"><figure>
    <img src="./img/img29.png" alt="img29"><br>
    <figcaption>Imagem 29.</figcaption>
</figure></div><br>

O serviço **SMB** (Server Message Block), escutando na porta 445 do host analisado, foi identificado como ativo. Foi utilizado o script `smb-os-discovery` e `smb-enum-shares` do **Nmap** para coletar informações sobre o sistema operacional e os compartilhamentos SMB disponíveis no servidor. O resultado mostrou que a porta 445 está aberta e o serviço `microsoft-ds` está em execução, indicando um servidor SMB ativo. Embora neste scan específico não tenham sido retornadas informações detalhadas sobre compartilhamentos ou sistema operacional, a presença do serviço SMB aberto pode representar riscos de segurança, como exposição de dados compartilhados, possíveis vulnerabilidades do protocolo SMB (especialmente em versões antigas) e potenciais vetores para ataques de ransomware ou acesso não autorizado. Recomenda-se restringir o acesso à porta 445 apenas a IPs autorizados, manter o servidor atualizado com os patches de segurança mais recentes e, se possível, utilizar autenticação forte e monitoramento contínuo do serviço.

Foi realizada uma tentativa de conexão ao serviço **SMB** na porta 445 utilizando o utilitário **smbclient**. Na primeira tentativa, sem especificar a versão do protocolo, a conexão falhou devido à incompatibilidade com o protocolo SMB1, indicando que o servidor não aceita esse protocolo mais antigo. Nas tentativas seguintes, foram explicitamente definidas as versões mínimas e máximas do protocolo para SMB2 e SMB3, conseguindo conectar ao compartilhamento administrativo `IPC$`. Contudo, ao tentar listar os arquivos ou diretórios disponíveis, foram retornados erros do tipo `NT_STATUS_OBJECT_NAME_NOT_FOUND`, indicando que não há objetos visíveis para o cliente anonimamente. Além disso, ao tentar conexão via porta 139, o comportamento foi o mesmo, com acesso restrito e ausência de listagem de recursos. Esses resultados indicam que o servidor SMB estava configurado para desabilitar SMB1, o que é positivo para a segurança, e restringia o acesso anônimo a recursos compartilhados, reduzindo a exposição a ataques comuns via SMB. A imagem 30 exibe essa tentativa de conexão.

<div align="center"><figure>
    <img src="./img/img30.png" alt="img30"><br>
    <figcaption>Imagem 30.</figcaption>
</figure></div><br>

O servidor web, identificado na porta 80 do host analisado, respondeu com sucesso ao comando `curl -I`, retornando o código HTTP `200 OK`. O servidor utilizava o **Nginx** como software de hospedagem e estava executando **PHP 7.3.14**, conforme indicado pelo cabeçalho `X-Powered-By`. Foram observados cabeçalhos de segurança importantes, como `X-Content-Type-Options: nosniff`, `X-XSS-Protection: 1; mode=block` e `X-Frame-Options: SAMEORIGIN`, que ajudam a mitigar ataques de injeção de código, XSS e clickjacking, respectivamente. Além disso, o servidor estava configurado para não armazenar cache (`Cache-Control: no-store, no-cache, must-revalidate`), o que é positivo para evitar o armazenamento de informações sensíveis no cache do navegador. No entanto, a presença do cabeçalho `X-Powered-By` pode expor a versão do PHP, o que pode ser explorado por atacantes para identificar vulnerabilidades específicas. Recomenda-se, portanto, ocultar ou remover esse cabeçalho para reduzir o nível de exposição do servidor.

O serviço **Zabbix**, acessível na porta 10051/10052 do host analisado, apresentou uma interface web acessível via HTTP, conforme verificado pela requisição `curl`. O conteúdo retornado indicava que se tratava de uma instalação padrão do Zabbix docker, incluindo a página de login onde são solicitados usuário e senha para autenticação. A presença dessa interface pública pode representar um risco de exposição se não houver proteção adequada, como autenticação forte e restrição de acesso, já que interfaces de monitoramento são alvos frequentes de tentativas de acesso indevido.

Além disso, foi executado o comando `zabbix_get -s 10.10.30.117 -p 10051 -k agent.ping`, conforme imagem 31 abaixo, que retornou a mensagem: 
`zabbix_get [2134]: Check access restrictions in Zabbix agent configuration`. Essa mensagem indicava que o agente **Zabbix** possuía restrições de acesso configuradas, o que é uma boa prática para limitar conexões não autorizadas. Recomenda-se garantir o uso de HTTPS para criptografia da comunicação, configurar autenticação robusta, limitar o acesso via firewall e manter o software atualizado para reduzir vulnerabilidades.

<div align="center"><figure>
    <img src="./img/img31.png" alt="img31"><br>
    <figcaption>Imagem 31.</figcaption>
</figure></div><br>

<a name="item1.4"><h4>1.4. Inventário Técnico e Classificação dos Ativos de Rede</h4></a>[Back to summary](#item1)

Bom, basicamente a partir daqui a parte prática/técnica já foi finalizada, aqui se inicia a construção do relatório técnico e dos elementos nele presente. Um dos elementos muito importante é o inventário técnico que reune todas as informações de redes, hosts, ip, portas e serviços. É aqui que acontece a classificação ou mapeamento dos ativos da rede, esses ativos são justamente esses elementos citados. 




<a name="item1.5"><h4>1.5. Diagnóstico e Recomendações</h4></a>[Back to summary](#item1)


| Porta       | Serviço          | Riscos Identificados                     | Observações                          | Recomendações           |
|-------------|------------------|----------------------------------------|-----------------------------|-----------------------------|
| 21    | FTP   | Protocolo inseguro          | Não há criptografia das informações em trânsito | Usar protocolo SFTP (FTP sobre SSH)  |
| 3306  | MySQL | Autenticação por senha fraca  | -            | Usar autenticação forte |
| 3306  | MySQL | Exposição de informações detalhadas a usuários não autorizados   | -     | Configurar firewall para limitar IPs autorizados |
| 3306  | MySQL | Permitir conexões de qualquer IP     | -         | Configurar firewall para limitar IPs autorizados |
| 389   | LDAP  | Exposição de informações sensíveis via consultas anônimas   | O LDAP permite consultas sem autenticação, podendo vazar dados  | Desabilitar consultas anônimas; exigir autenticação |
| 389   | LDAP  | Possibilidade de enumeração de usuários e grupos | Atacantes podem listar usuários e grupos da organização | Restringir acesso e aplicar controles de acesso |
| 389   | LDAP  | Falta de criptografia (LDAP simples) | Tráfego é enviado em texto claro, vulnerável a sniffing | Usar LDAPS (LDAP sobre TLS/SSL) para criptografia  |
| 139 / 445  | SMB | Uso de protocolo obsoleto (SMB1) | SMB1 está desabilitado, o que é positivo para segurança | Manter SMB1 desabilitado; usar SMB2/SMB3 |
| 139 / 445  | SMB | Possibilidade de acesso anônimo limitado | Compartilhamento IPC$ acessível, mas sem listagem de arquivos | Restringir ainda mais acesso |
| 80   | Apache HTTP | Exposição de versão do PHP via cabeçalho `X-Powered-By` | Presença do cabeçalho pode facilitar reconhecimento de vulnerabilidades | Remover ou ocultar cabeçalho `X-Powered-By` para reduzir exposição |
| 10051/10052 | Zabbix Proxy/Agent | Interface web pública sem HTTPS | - | Usar HTTPS |
| 10051/10052 | Zabbix Proxy/Agent | Risco de acesso indevido |  - | Configurar autenticação forte |
| 10051/10052 | Zabbix Proxy/Agent | Possibilidade de acesso remoto não autorizado ao agente | Agente Zabbix com restrições de acesso configuradas (boa prática) | Limitar acesso via firewall |
| 10051/10052 | Zabbix Proxy/Agent | Vulnerabilidades devido a software desatualizado | - | Manter software atualizado |

<a name="item1.6"><h4>1.6. Documentação Técnica</h4></a>[Back to summary](#item1)








